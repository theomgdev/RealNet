# RealNet: Beyin Ä°lhamlÄ± KatmansÄ±z Sinir Mimarisi

![License](https://img.shields.io/badge/license-MIT-blue.svg)

[ğŸ‡ºğŸ‡¸ Read in English](./README.md) | [ğŸ“œ Orijinal Manifesto (Eski Metin)](./MANIFESTO.md)

## Ã–zet

RealNet, geleneksel katmanlÄ± mimarilerden (FNN'ler, CNN'ler, Transformer'lar) temelden ayrÄ±lan, yapay sinir aÄŸlarÄ±nda yeni bir paradigma sunar. Biyolojik beynin kaotik ancak verimli baÄŸlantÄ±sallÄ±ÄŸÄ±ndan ilham alan RealNet, her nÃ¶ronun diÄŸer her nÃ¶ronla baÄŸlantÄ± kurma potansiyeline sahip olduÄŸu, tamamen birbirine baÄŸlÄ±, katmansÄ±z bir topoloji kullanÄ±r. Bu mimari, Ã§ok boyutlu veri iletimini (2D'den 5D+'ya) kolaylaÅŸtÄ±rÄ±r ve dairesel veri dÃ¶ngÃ¼leri aracÄ±lÄ±ÄŸÄ±yla kÄ±sa sÃ¼reli hafÄ±zanÄ±n, benzersiz bir "Ä°leri AteÅŸle, Ä°leri BaÄŸla" (Fire Forward, Wire Forward - FFWF) Ã¶ÄŸrenme algoritmasÄ± aracÄ±lÄ±ÄŸÄ±yla ise uzun sÃ¼reli hafÄ±zanÄ±n ortaya Ã§Ä±kmasÄ±nÄ± saÄŸlar. RealNet, statik veri setlerinin kÄ±sÄ±tlamalarÄ± olmaksÄ±zÄ±n aktif Ã¶ÄŸrenme, rÃ¼ya gÃ¶rme ve Ã¶z-dÃ¼zenleme iÃ§in teorik yetenekler sergiler.

## 1. GiriÅŸ

Derin Ã¶ÄŸrenmedeki hakim yaklaÅŸÄ±m, yapÄ±landÄ±rÄ±lmÄ±ÅŸ katmanlara ve geri yayÄ±lÄ±ma (backpropagation) dayanÄ±r. Etkili olsalar da, bu yÃ¶ntemler genellikle doÄŸal sinir sistemlerinin dinamik uyarlanabilirliÄŸinden ve biyolojik makullÃ¼ÄŸÃ¼nden yoksundur. RealNet, beynin "nÃ¶ron Ã§orbasÄ±" yaklaÅŸÄ±mÄ±nÄ± taklit ederek bu sÄ±nÄ±rlamalarÄ± ele alÄ±r.

RealNet'te "katman" kavramÄ± ortadan kaldÄ±rÄ±lmÄ±ÅŸtÄ±r. AÄŸ, yÃ¶nlÃ¼lÃ¼ÄŸÃ¼n dayatÄ±lmak yerine kendiliÄŸinden ortaya Ã§Ä±ktÄ±ÄŸÄ± kaotik bir baÄŸlantÄ± aÄŸÄ±dÄ±r. Bu yapÄ± ÅŸunlara olanak tanÄ±r:
*   **Dinamik Topoloji:** AÄŸ, etkin yapÄ±sÄ±nÄ± veri akÄ±ÅŸÄ±na gÃ¶re uyarlayabilir.
*   **Zamansal Ä°ÅŸleme:** Bilgi, karmaÅŸÄ±k zamansal baÄŸÄ±mlÄ±lÄ±klara izin verecek ÅŸekilde sÃ¼rekli zaman adÄ±mlarÄ±nda iÅŸlenir.
*   **Ã–z-DÃ¼zenleme:** AÄŸ, Hebbian Ã¶ÄŸrenmeye benzer ancak zamansal uygulamasÄ±nda farklÄ± olan aktivite korelasyonlarÄ±na dayanarak kendi baÄŸlantÄ±larÄ±nÄ± iyileÅŸtirir.

## 2. Teorik Mimari

### 2.1. Topoloji ve BaÄŸlantÄ±sallÄ±k
AÄŸ, bir nÃ¶ron ve baÄŸlantÄ± koleksiyonundan oluÅŸur. BaÄŸlantÄ±larÄ±n yalnÄ±zca bitiÅŸik katmanlar arasÄ±nda olduÄŸu FNN'lerin aksine, bir RealNet nÃ¶ronu sistemdeki diÄŸer herhangi bir nÃ¶rondan girdi alabilir ve ona Ã§Ä±ktÄ± gÃ¶nderebilir.
*   **Kaotik BaÄŸlantÄ±sallÄ±k:** Bu, karmaÅŸÄ±k, tekrarlayan (recurrent) yapÄ±larÄ±n oluÅŸumuna izin verir.
*   **Dairesel DÃ¶ngÃ¼ler (KÄ±sa SÃ¼reli HafÄ±za):** Veriler geri besleme dÃ¶ngÃ¼lerinde sÄ±kÄ±ÅŸÄ±p kalabilir, bu da etkili bir ÅŸekilde kÄ±sa sÃ¼reli bir hafÄ±za tamponu gÃ¶revi gÃ¶rÃ¼r. Bu dÃ¶ngÃ¼ler periyodik sinyaller yayarak aÄŸÄ±n durumunu birden fazla zaman adÄ±mÄ±nda etkiler.
*   **Boyutluluk:** BaÄŸlantÄ± modeli, geleneksel katmanlarÄ±n dÃ¼z temsillerini aÅŸarak keyfi boyutlarda veri temsilini destekler.

### 2.2. NÃ¶ron Dinamikleri
Her nÃ¶ron, zamanla geliÅŸen bir iÃ§ durum (state) tutar.
*   **BirikmiÅŸ Ä°statistikler:** NÃ¶ronlar ortalama, maksimum ve minimum ateÅŸleme deÄŸerlerini takip eder.
*   **Uyarlanabilir DuyarlÄ±lÄ±k:** Bu istatistikler, aktivasyon fonksiyonunu dinamik olarak Ã¶lÃ§eklendirmek iÃ§in kullanÄ±lÄ±r, bÃ¶ylece nÃ¶ronun tekrarlayan arka plan gÃ¼rÃ¼ltÃ¼sÃ¼ne alÄ±ÅŸÄ±rken yeni uyaranlara karÅŸÄ± duyarlÄ± kalmasÄ± saÄŸlanÄ±r.

### 2.3. Aktivasyon Fonksiyonu: Uyarlanabilir Tanh
RealNet, aÄŸ sinyallerinin dinamik aralÄ±ÄŸÄ±nÄ± iÅŸlemek iÃ§in tasarlanmÄ±ÅŸ Ã¶zel, uyarlanabilir bir aktivasyon fonksiyonu kullanÄ±r. DoygunluÄŸu Ã¶nlemek ve verimli gradyan akÄ±ÅŸÄ±nÄ± (kavramsal olarak) saÄŸlamak iÃ§in dinamik Ã¶lÃ§eklendirme ve normalizasyon iÃ§erir.

**Matematiksel FormÃ¼lasyon:**

$$y = \frac{\tanh\left( k \cdot \frac{x - x_{ort}}{ \frac{x_{max} - x_{min}}{2} + \frac{x_{max} + x_{min} - 2x_{ort}}{2} \cdot \text{sgn}(x - x_{ort}) } \right)}{\tanh(k)}$$

Burada:
*   $x$ girdi deÄŸeridir.
*   $x_{ort}, x_{max}, x_{min}$ nÃ¶ronun Ã§alÄ±ÅŸan istatistikleridir.
*   $k$ bir sabittir (AltÄ±n Oran $\phi \approx 1.618$ veya $3$ Ã¶nerilir).
*   $\text{sgn}(z) = \frac{z}{|z| + \epsilon}$ tÃ¼revlenebilir bir iÅŸaret fonksiyonudur.

**Mekanizma:**
1.  **Dinamik Ã–lÃ§eklendirme:** Payda, $x$'in ortalamanÄ±n Ã¼zerinde veya altÄ±nda olmasÄ±na baÄŸlÄ± olarak ayarlanÄ±r ve girdiyi nÃ¶ronun tarihsel aralÄ±ÄŸÄ±na gÃ¶re etkili bir ÅŸekilde normalleÅŸtirir.
2.  **Normalizasyon:** $\tanh(k)$ ile bÃ¶lme, girdiler tarihsel uÃ§ noktalara Ã§arpsa bile Ã§Ä±ktÄ± aralÄ±ÄŸÄ±nÄ±n kesinlikle $[-1, 1]$ olmasÄ±nÄ± saÄŸlar.
3.  **AlÄ±ÅŸma (Habituation):** Bir nÃ¶ron tutarlÄ± bir ÅŸekilde ateÅŸlendiÄŸinde, $x_{ort}$ kayar ve fonksiyon nÃ¶ronu o kararlÄ± duruma karÅŸÄ± duyarsÄ±zlaÅŸtÄ±rÄ±r, tekrarlayan gÃ¼rÃ¼ltÃ¼yÃ¼ filtreler ve anormallikleri (sÄ±Ã§ramalarÄ±) vurgular.

## 3. Algoritmik Ã‡ekirdek

### 3.1. Ã‡Ä±karÄ±m Motoru (Inference Engine)
RealNet'te Ã§Ä±karÄ±m, tek geÃ§iÅŸli bir yayÄ±lÄ±m deÄŸil, zaman adÄ±mlÄ± bir sÃ¼reÃ§tir.
1.  **Biriktirme:** BaÄŸlantÄ±lar, Ã¶nceki zaman adÄ±mÄ±ndan tamponlanmÄ±ÅŸ deÄŸerleri hedef nÃ¶ronlara iletir.
2.  **Durum GÃ¼ncellemesi:** (Ä°steÄŸe baÄŸlÄ±) Mevcut duruma gÃ¶re bir eÄŸitim adÄ±mÄ± (Standart veya RÃ¼ya) yÃ¼rÃ¼tÃ¼lÃ¼r.
3.  **Aktivasyon:** NÃ¶ronlar birikmiÅŸ girdileri uyarlanabilir aktivasyon fonksiyonu aracÄ±lÄ±ÄŸÄ±yla iÅŸler.
4.  **YayÄ±lÄ±m:** NÃ¶ronlar sÄ±fÄ±rlanÄ±r ve Ã§Ä±ktÄ±larÄ± baÄŸlantÄ±lara iletir.
5.  **Ä°letim:** BaÄŸlantÄ±lar Ã§Ä±ktÄ±larÄ± aÄŸÄ±rlÄ±klarla Ã§arpar ve sonucu *bir sonraki* zaman adÄ±mÄ± iÃ§in tamponlar.

Biriktirme ve iletimin bu ÅŸekilde ayrÄ±lmasÄ±, yarÄ±ÅŸ koÅŸullarÄ±nÄ± (race conditions) Ã¶nler ve sÄ±ralÄ± donanÄ±m Ã¼zerinde paralel iÅŸlemeyi simÃ¼le eder.

### 3.2. EÄŸitim ProtokolÃ¼: Ä°leri AteÅŸle, Ä°leri BaÄŸla (FFWF)
RealNet, zamansal farkÄ±ndalÄ±ÄŸa sahip yerel bir Ã¶ÄŸrenme kuralÄ± iÃ§in geri yayÄ±lÄ±mÄ± terk eder.
*   **Kavram:** "Birlikte AteÅŸle, Birlikte BaÄŸla" (uzamsal korelasyon) yerine FFWF, "Ä°leri AteÅŸle, Ä°leri BaÄŸla" (zamansal nedensellik) Ã¼zerine odaklanÄ±r. Bir nÃ¶ronun ateÅŸlenmesinin, bir sonraki zaman adÄ±mÄ±nda baÅŸka bir nÃ¶ronun ateÅŸlenmesini *tahmin ettiÄŸi* baÄŸlantÄ±larÄ± gÃ¼Ã§lendirir.
*   **Mekanizma:**
    *   **Pozitif Korelasyon:** NÃ¶ron A (t-1) pozitif ateÅŸler ve NÃ¶ron B (t) pozitif ateÅŸlerse, $W_{AB}$ aÄŸÄ±rlÄ±ÄŸÄ± artÄ±rÄ±lÄ±r.
    *   **Negatif Korelasyon:** NÃ¶ron A (t-1) pozitif ateÅŸler ve NÃ¶ron B (t) negatif ateÅŸlerse, $W_{AB}$ azaltÄ±lÄ±r (engelleyici/inhibitory).
    *   **Ã‡Ã¼rÃ¼me (Decay):** AteÅŸlemeyen nÃ¶ronlardan gelen veya onlara giden baÄŸlantÄ±lar sÄ±fÄ±ra doÄŸru Ã§Ã¼rÃ¼tÃ¼lÃ¼r, ilgisiz yollar budanÄ±r.
*   **AÄŸÄ±rlÄ±k PatlamasÄ± KontrolÃ¼:** Basit aÄŸÄ±rlÄ±k Ã§Ã¼rÃ¼mesi yerine algoritma, aÄŸÄ±rlÄ±klarÄ± kaynaÄŸÄ±n hedefe olan *dolaylÄ±* katkÄ±sÄ±na gÃ¶re ayarlayarak kontrolden Ã§Ä±kan geri besleme dÃ¶ngÃ¼lerini Ã¶nler.

### 3.3. RÃ¼ya EÄŸitimi (DamÄ±tma/Distillation)
Her adÄ±mda aÃ§Ä±k bir denetim olmadan yakÄ±nsamak (converge) iÃ§in RealNet "RÃ¼ya EÄŸitimi"ni kullanÄ±r.
*   **SÃ¼reÃ§:** AÄŸ periyodik olarak dÄ±ÅŸ girdiden koparÄ±lÄ±r. Ã‡Ä±ktÄ± nÃ¶ronlarÄ± istenen deÄŸerlere (bir veri setinden) sabitlenir/kilitlenir.
*   **DamÄ±tma:** AÄŸ iÃ§ dÃ¶ngÃ¼ler Ã§alÄ±ÅŸtÄ±rÄ±r. FFWF algoritmasÄ± bu "rÃ¼ya" durumlarÄ±nÄ± geriye doÄŸru (nedensel olarak) yayar ve doÄŸal olarak bu Ã§Ä±ktÄ±lara yol aÃ§acak yollarÄ± gÃ¼Ã§lendirir.
*   **Temellendirme (Grounding):** Bu sÃ¼reÃ§, soyut iÃ§ temsilleri somut hedef Ã§Ä±ktÄ±lara temellendirir ve kaotik kÄ±sa sÃ¼reli hafÄ±zayÄ± etkili bir ÅŸekilde yapÄ±landÄ±rÄ±lmÄ±ÅŸ uzun sÃ¼reli aÄŸÄ±rlÄ±klara damÄ±tÄ±r.

## 4. YakÄ±nsama ve KararlÄ±lÄ±k
RealNet'te yakÄ±nsama, zamansal girdi Ã¶rÃ¼ntÃ¼lerini istenen Ã§Ä±ktÄ± durumlarÄ±na eÅŸleyen kararlÄ±, Ã¶ngÃ¶rÃ¼cÃ¼ yollarÄ±n oluÅŸumu olarak tanÄ±mlanÄ±r.
*   **Ã–z-DÃ¼zenleme:** Uyarlanabilir aktivasyon fonksiyonu, aÅŸÄ±rÄ± aktif nÃ¶ronlarÄ± doÄŸal olarak sÃ¶nÃ¼mler.
*   **Budama:** FFWF algoritmasÄ± zayÄ±f baÄŸlantÄ±larÄ± sÃ¼rekli olarak budayarak aÄŸÄ± seyreltir (sparsifying).
*   **Gelecek Tahmini:** AÄŸ, kendi gelecek durumlarÄ±nÄ± tahmin etmeyi doÄŸal olarak Ã¶ÄŸrenir ve iÃ§sel sÃ¼rprizi (serbest enerji ilkesi) en aza indirir.

## 5. Vizyon ve Gelecek YÃ¶nelimleri

RealNet, "Organik Yapay Zeka"ya doÄŸru bir adÄ±mÄ± temsil eder. Sadece statik verileri sÄ±nÄ±flandÄ±rmak iÃ§in deÄŸil, sÃ¼rekli bir veri akÄ±ÅŸÄ±nda var olmak, deneyimlemek ve uyum saÄŸlamak iÃ§in tasarlanmÄ±ÅŸtÄ±r.

*   **Ã–lÃ§eklenebilirlik:** KatmansÄ±z doÄŸa, tÃ¼m aÄŸÄ± yeniden eÄŸitmeden yeni nÃ¶ronlarÄ±n sorunsuz bir ÅŸekilde eklenmesine izin verir.
*   **AÄŸlar ArasÄ± Ä°letiÅŸim:** Birden fazla RealNet doÄŸrudan baÄŸlanabilir, iÃ§ durumlarÄ± ve "dÃ¼ÅŸÃ¼nceleri" ayrÄ±k tokenlara kodlama/kod Ã§Ã¶zme ihtiyacÄ± olmadan paylaÅŸabilir.
*   **GerÃ§ek Ã‡ok Modluluk (Multimodality):** Verileri zaman iÃ§indeki ham sinyaller olarak iÅŸleyerek RealNet; metin, ses ve videoyu temel olarak aynÄ± ÅŸekilde ele alÄ±r: Ã¶ÄŸrenilecek ve tahmin edilecek zamansal Ã¶rÃ¼ntÃ¼ler.

## Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.
