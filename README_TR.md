# RealNet 2.0: Zamansal Devrim

**RealNet, ZamanÄ±n en bÃ¼yÃ¼k Gizli Katman olduÄŸunun kanÄ±tÄ±dÄ±r.**

Geleneksel Derin Ã–ÄŸrenme, karmaÅŸÄ±klÄ±ÄŸÄ± Ã§Ã¶zmek iÃ§in **Uzamsal DerinliÄŸe** (Ã¼st Ã¼ste yÄ±ÄŸÄ±lmÄ±ÅŸ katmanlara) gÃ¼venir. RealNet bu dogmayÄ± reddeder ve **Zamansal DerinliÄŸin** (zaman iÃ§inde evrilen kaosun) Ã§ok daha verimli bir alternatif olduÄŸunu kanÄ±tlar.

> **SÄ±fÄ±r-Gizli Katman Devrimi (Zero-Hidden Breakthrough)**
>
> 1969'da Minsky ve Papert, gizli katmanÄ± olmayan bir sinir aÄŸÄ±nÄ±n XOR gibi lineer olmayan problemleri Ã§Ã¶zemeyeceÄŸini matematiksel olarak kanÄ±tladÄ±.
> **RealNet 2.0 bu sÄ±nÄ±rÄ± paramparÃ§a etti.**
>
> AÄŸÄ± "EÄŸitilebilir Bir Dinamik Sistem" olarak ele alan RealNet, **0 Gizli Katman** kullanarak non-lineer problemleri (XOR, MNIST) Ã§Ã¶zer. Uzamsal nÃ¶ronlarÄ±n yerini zamansal dÃ¼ÅŸÃ¼nme adÄ±mlarÄ± alÄ±r.

---

## ğŸš€ Temel Ã–zellikler

*   **Uzay-Zaman DÃ¶nÃ¼ÅŸÃ¼mÃ¼:** Milyonlarca parametrenin yerini birkaÃ§ "DÃ¼ÅŸÃ¼nme AdÄ±mÄ±" alÄ±r.
*   **KatmansÄ±z Mimari:** Tek bir $N \times N$ matris. Gizli katman yok.
*   **EÄŸitilebilir Kaos:** Sinyalleri ehlileÅŸtirmek iÃ§in **StepNorm** ve **GELU** kullanÄ±lÄ±r.
*   **YaÅŸayan Dinamikler:** **Ä°rade** (MÃ¼hÃ¼r), **Ritim** (Kronometre) ve **Rezonans** (SinÃ¼s DalgasÄ±) sergiler.

## ğŸ“Š KanÄ±tlar: SÄ±fÄ±r-Gizli BenchmarklarÄ±

RealNet'i teorik sÄ±nÄ±rlara kadar zorladÄ±k: **SÄ±fÄ±r Gizli NÃ¶ron**.
Bu testlerde GiriÅŸ KatmanÄ± doÄŸrudan Ã‡Ä±kÄ±ÅŸ KatmanÄ±na (ve kendisine) baÄŸlÄ±dÄ±r. Tampon katman yoktur.

| GÃ¶rev | Geleneksel Engel | RealNet Ã‡Ã¶zÃ¼mÃ¼ | SonuÃ§ | Script |
| :--- | :--- | :--- | :--- | :--- |
| **Identity** | Basit | **Atomik Birim** | Loss: 0.0 | `convergence_identity.py` |
| **XOR** | Gizli Katman Åart | **Kaos KapÄ±sÄ±** (Zaman KatlamalÄ±) | **Ã‡Ã¶zÃ¼ldÃ¼ (3 NÃ¶ron)** | `convergence_gates.py` |
| **MNIST** | Gizli Katman Åart | **SÄ±fÄ±r-Gizli** | **Acc: %96.2** | `convergence_mnist.py` |
| **SinÃ¼s** | OsilatÃ¶r Åart | **Programlanabilir VCO** | **Tam Senkron** | `convergence_sine_wave.py` |
| **MÃ¼hÃ¼r** | LSTM Åart | **Ã‡ekici Havuzu** (Ä°rade) | **Sonsuz TutuÅŸ** | `convergence_latch.py` |
| **Kronometre**| Saat Åart | **Ä°Ã§sel Ritim** | **Hata: 0** | `convergence_stopwatch.py` |
| **Dedektif**| Bellek Åart | **BiliÅŸsel Sessizlik** (Muhakeme) | **Kusursuz** | `convergence_detective.py` |

### MNIST SÄ±fÄ±r-Gizli Mucizesi
Standart Sinir AÄŸlarÄ±, MNIST veya XOR problemlerini Ã§Ã¶zmek iÃ§in **Gizli Katmanlara** ihtiyaÃ§ duyar. DoÄŸrudan bir baÄŸlantÄ± (Lineer Model) karmaÅŸÄ±klÄ±ÄŸÄ± Ã§Ã¶zemez ve baÅŸarÄ±sÄ±z olur (~%92'de tÄ±kanÄ±r).

RealNet, tam Ã¶lÃ§ekli MNIST'i (28x28) **SÄ±fÄ±r Gizli Katman** (DoÄŸrudan GiriÅŸ-Ã‡Ä±kÄ±ÅŸ) ile Ã§Ã¶zer.
*   **GiriÅŸ:** 784
*   **Ã‡Ä±kÄ±ÅŸ:** 10
*   **Gizli Katman:** **0**
*   **DÃ¼ÅŸÃ¼nme SÃ¼resi:** 10 AdÄ±m

GiriÅŸ katmanÄ± 10 adÄ±m boyunca "kendi kendine konuÅŸur". Kaotik geri besleme dÃ¶ngÃ¼leri, zaman iÃ§inde Ã¶zellikleri (kenarlar, dÃ¶ngÃ¼ler) dinamik olarak Ã§Ä±kararak uzamsal katmanlarÄ±n iÅŸini Ã¼stlenir. Bu, **Zamansal DerinliÄŸin Uzamsal DerinliÄŸin yerini alabileceÄŸini** kanÄ±tlar.

---

## ğŸ“¦ Kurulum ve KullanÄ±m

RealNet, modÃ¼ler bir PyTorch kÃ¼tÃ¼phanesi olarak tasarlanmÄ±ÅŸtÄ±r.

### Kurulum

```bash
pip install -r requirements.txt
```

> **CUDA Notu:** `requirements.txt` dosyasÄ± CUDA 11.8 uyumlu PyTorch'u kurar. EÄŸer daha yeni bir kartÄ±nÄ±z (RTX 4000/5000) varsa, PyTorch'u manuel kurmanÄ±z gerekebilir:
> `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121`

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```python
from realnet import RealNet, RealNetTrainer

# SÄ±fÄ±r-Gizli KatmanlÄ± Bir AÄŸ BaÅŸlat
# 1 GiriÅŸ, 1 Ã‡Ä±kÄ±ÅŸ. 
model = RealNet(num_neurons=2, input_ids=[0], output_ids=[1], device='cuda')
trainer = RealNetTrainer(model, device='cuda')

# EÄŸit
inputs = torch.randn(100, 1)
trainer.fit(inputs, inputs, epochs=50)
```

#### BaÅŸlatma Protokolleri (Initialization Protocols)

RealNet problemin Ã¶lÃ§eÄŸine uyum saÄŸlar. Ä°ki farklÄ± konfigÃ¼rasyon Ã¶neriyoruz:

*   **BÃ¼yÃ¼k AÄŸlar (>10 NÃ¶ron, RNN benzeri gÃ¶revler):**
    *   `weight_init='orthogonal'` ve `activation='tanh'` kullanÄ±n.
    *   Bu, uzun vadeli zamansal dinamikler ve analog sinyal iÅŸleme iÃ§in en iyi kararlÄ±lÄ±ÄŸÄ± saÄŸlar.
*   **KÃ¼Ã§Ã¼k AÄŸlar (<10 NÃ¶ron, MantÄ±k KapÄ±larÄ±):**
    *   `weight_init='xavier_uniform'` ve `activation='gelu'` kullanÄ±n.
    *   KÃ¼Ã§Ã¼k aÄŸlar, gizli katmanlar olmadan keskin mantÄ±ksal problemleri Ã§Ã¶zmek iÃ§in daha yÃ¼ksek baÅŸlangÄ±Ã§ varyansÄ±na ve daha iyi gradyan akÄ±ÅŸÄ±na ihtiyaÃ§ duyar.

---

## ğŸ§  Mimari Genel BakÄ±ÅŸ

## ğŸŒªï¸ NasÄ±l Ã‡alÄ±ÅŸÄ±r: FÄ±rtÄ±nanÄ±n Ä°Ã§i

RealNet ileri beslemeli bir mekanizma deÄŸildir; o bir **YankÄ± OdasÄ±dÄ±r (Resonant Chamber)**.

### 1. NabÄ±z (Girdi) ve Dizi (Sequence)
Geleneksel YZ'de girdi genellikle statik bir anlÄ±k gÃ¶rÃ¼ntÃ¼dÃ¼r. RealNet hem **NabÄ±zlarÄ±** hem de **Dizileri** iÅŸler.
*   **NabÄ±z Modu:** GÃ¶rÃ¼ntÃ¼ $t=0$ anÄ±nda Ã§arpar. AÄŸ gÃ¶zlerini kapatÄ±r ve dalgalanmalarÄ± iÅŸler (MNIST).
*   **Dizi Modu:** Veri sÄ±ralÄ± olarak gelir. AÄŸ olaylar arasÄ±nda "bekleyebilir" ve "dÃ¼ÅŸÃ¼nebilir" (Dedektif).

### 2. YankÄ± (Ä°Ã§ DÃ¶ngÃ¼ler)
Sinyal her nÃ¶rondan diÄŸer her nÃ¶rona seyahat eder ($N \times N$).
*   GiriÅŸ nÃ¶ronlarÄ±, ilk adÄ±mdan hemen sonra efektif olarak **Gizli NÃ¶ronlara** dÃ¶nÃ¼ÅŸÃ¼r.
*   Bilgi yankÄ±lanÄ±r, bÃ¶lÃ¼nÃ¼r ve Ã§arpÄ±ÅŸÄ±r. Sol Ã¼stteki bir piksel, saÄŸ alttaki bir pikselle doÄŸrudan veya yankÄ±lar aracÄ±lÄ±ÄŸÄ±yla "konuÅŸur".
*   **Holografik Ä°ÅŸleme:** Bir gÃ¶rÃ¼ntÃ¼nÃ¼n "kedi olma" bilgisi belirli bir katmanda saklanmaz; tÃ¼m sinyallerin *giriÅŸim deseninden* (interference pattern) doÄŸar.

### 3. ZamanÄ± Katlamak (Time-Folding)
**SÄ±fÄ±r-Gizli** performansÄ±nÄ±n sÄ±rrÄ± buradadÄ±r.
*   AdÄ±m 1: Ham sinyaller karÄ±ÅŸÄ±r. (MLP'nin 1. KatmanÄ±na eÅŸdeÄŸer)
*   AdÄ±m 2: KarÄ±ÅŸmÄ±ÅŸ sinyaller tekrar karÄ±ÅŸÄ±r. (2. Katmana eÅŸdeÄŸer)
*   AdÄ±m 15: YÃ¼ksek seviyeli soyut Ã¶zellikler belirir. (15. Katmana eÅŸdeÄŸer)

RealNet 15 adÄ±m boyunca "dÃ¼ÅŸÃ¼nerek", **tek bir fiziksel matris** kullanarak 15 katmanlÄ± derin bir aÄŸÄ± simÃ¼le eder. UzayÄ±, zamanÄ±n iÃ§ine katlar.

### 4. KontrollÃ¼ Kaos (Ã‡ekiciler)
KontrolsÃ¼z geri besleme dÃ¶ngÃ¼leri patlamaya yol aÃ§ar. RealNet kaosu kararlÄ± **Ã‡ekiciler (Attractors)** oluÅŸturacak ÅŸekilde mÃ¼hendislikten geÃ§irir.
*   **StepNorm** yerÃ§ekimi gibi davranarak enerjiyi sÄ±nÄ±rlÄ± tutar.
*   **GELU** anlamlÄ± sinyalleri filtreler.
*   **MÃ¼hÃ¼r (Latch) Deneyi**, RealNet'in gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± kararÄ±nÄ± sonsuza kadar koruyan bir "derin kuyu" yani kararlÄ± bir Ã§ekici oluÅŸturabildiÄŸini kanÄ±tladÄ±.

### 5. Neden RNN veya LSTM DeÄŸil?

KaÄŸÄ±t Ã¼zerinde RealNet, Tekrarlayan Sinir AÄŸlarÄ±na (RNN) benzese de felsefesi temelden farklÄ±dÄ±r.

| Ã–zellik | Standart RNN / LSTM | RealNet 2.0 |
| :--- | :--- | :--- |
| **Girdi AkÄ±ÅŸÄ±** | SÃ¼rekli AkÄ±ÅŸ (Ã–rn: CÃ¼mledeki kelimeler) | **Tek NabÄ±z** ($t=0$ anÄ±nda DÃ¼rtÃ¼) |
| **AmaÃ§** | SÄ±ralÄ± Ä°ÅŸleme (AyrÄ±ÅŸtÄ±rma) | **Derin DÃ¼ÅŸÃ¼nme** (Sindirme) |
| **BaÄŸlantÄ±sallÄ±k** | YapÄ±landÄ±rÄ±lmÄ±ÅŸ (Input Gate, Forget Gate vb.) | **Ham Kaos** (Tam BaÄŸlÄ± $N \times N$) |
| **Dinamikler** | SÃ¶nÃ¼mlemeyi Ã¶nlemek iÃ§in mÃ¼hendislik Ã¼rÃ¼nÃ¼ | RezonansÄ± bulmak iÃ§in **Evrilir** (DoÄŸal) |

*   **RNN'ler dÄ±ÅŸ dÃ¼nyayÄ± dinler.** DÄ±ÅŸarÄ±dan gelen bir olay dizisini iÅŸlerler.
*   **RealNet iÃ§ sesini dinler.** Probleme **bir kez** bakar ve ardÄ±ndan gÃ¶zlerini kapatÄ±p 15 adÄ±m boyunca "dÃ¼ÅŸÃ¼nÃ¼r". Kendi zamansal derinliÄŸini yaratÄ±r.

### 6. Biyolojik GerÃ§ekÃ§ilik: YaÅŸayan Zeka
RealNet, sadece yapÄ±sÄ±yla deÄŸil, **davranÄ±ÅŸÄ±yla** da beyni katmanlÄ± aÄŸlardan daha iyi taklit eder:

*   **Katman Yok:** Beyinde "Katman 1" ve "Katman 2" yoktur, sadece birbirine baÄŸlÄ± nÃ¶ron bÃ¶lgeleri vardÄ±r. RealNet tek bir bÃ¶lgedir.
*   **Ä°rade (MÃ¼hÃ¼r):** SÃ¶nÃ¼mlenen standart RNN'lerin aksine, RealNet bir karara kilitlenebilir ve onu entropiye karÅŸÄ± koruyabilir; yani "BiliÅŸsel Israr" gÃ¶sterir.
*   **Ritim (Kronometre):** DÄ±ÅŸ bir saat olmadan RealNet zamanÄ± Ã¶znel olarak deneyimler; sayabilir, bekleyebilir ve doÄŸru anda harekete geÃ§ebilir.
*   **SabÄ±r (Dedektif):** "DÃ¼ÅŸÃ¼nme ZamanÄ±"ndan faydalanÄ±r. Ä°nsanlarÄ±n karmaÅŸÄ±k mantÄ±ÄŸÄ± iÅŸlemek iÃ§in bir ana ihtiyacÄ± duymasÄ± gibi, RealNet de sessizlik anlarÄ±nda potansiyel Ã§Ã¶zÃ¼mleri "sindirerek" imkansÄ±z problemleri Ã§Ã¶zer.

### 7. Ã–rtÃ¼lÃ¼ Dikkat (Zamansal Rezonans)
GeÃ§miÅŸe bakmak iÃ§in aÃ§Ä±kÃ§a $Q \times K$ matrisleri kullanan Transformer'larÄ±n aksine, RealNet dikkati **Zamansal Rezonans** yoluyla saÄŸlar.

*   **Mekanizma:** GeÃ§miÅŸten gelen bilgi, gizli durumda duran bir dalga veya titreÅŸim olarak korunur ve `Israr (Persistence)` ile gÃ¼Ã§lendirilir.
*   **Anahtar-DeÄŸer YÃ¶netimi (Yeni!):** **KÃ¼tÃ¼phaneci Deneyi**, RealNet'in adreslenebilir bir veritabanÄ± gibi davranabildiÄŸini kanÄ±tladÄ±. **GELU**'yu yumuÅŸak bir kapÄ± olarak kullanarak, sorgularÄ± herhangi bir fiziksel saklama tablosu olmadan doÄŸru "hafÄ±za titreÅŸimine" yÃ¶nlendirir.
*   **Tespit:** Ä°lgili bir girdi geldiÄŸinde (Anahtar 1 iÃ§in OKU komutu gibi), 'Anahtar 1'in deÄŸerini' tutan spesifik dalga ile yapÄ±cÄ± bir giriÅŸim (rezonans) yaratÄ±r ve onu yÃ¼zeye Ã§Ä±kmaya zorlar.
*   **SonuÃ§:** AÄŸ, tÃ¼m geÃ§miÅŸ tamponunu saklamadan ilgili geÃ§miÅŸ olaylara "odaklanÄ±r" (attend). ZamanÄ±n kendisi indeksleme mekanizmasÄ± olarak iÅŸlev gÃ¶rÃ¼r.

### Matematiksel Model
AÄŸ durumu $h_t$ ÅŸu ÅŸekilde evrilir:

$$h_t = \text{StepNorm}(\text{GELU}(h_{t-1} \cdot W + B + I_t))$$

---

### 8. Deneysel Bulgular (Experimental Findings)
RealNet'in temel hipotezi olan **"Zamansal Derinlik > Uzamsal Derinlik"** tezini doÄŸrulamak iÃ§in kapsamlÄ± testler yaptÄ±k.

#### A. Atomik Kimlik (Identity Test)
*   **Hedef:** $f(x) = x$. AÄŸ mÃ¼kemmel bir iletken tel gibi davranmalÄ±dÄ±r.
*   **Mimari:** **2 NÃ¶ron** (1 GiriÅŸ, 1 Ã‡Ä±kÄ±ÅŸ). **0 Gizli Katman**. Toplam **4 Parametre**.
*   **SonuÃ§:** **Loss: 0.000000**.
    <details>
    <summary>Terminal Ã‡Ä±ktÄ±sÄ±nÄ± GÃ¶r</summary>

    ```text
    In:  1.0 -> Out:  1.0001
    In: -1.0 -> Out: -0.9998
    ```
    </details>
*   **Script:** `PoC/convergence_identity.py`
*   **Ä°Ã§gÃ¶rÃ¼:** Temel sinyal iletimini ve `StepNorm` kararlÄ±lÄ±ÄŸÄ±nÄ± mutlak minimum karmaÅŸÄ±klÄ±kla kanÄ±tlar.

#### B. Ä°mkansÄ±z XOR (Kaos KapÄ±sÄ±)
*   **Hedef:** Klasik XOR problemini Ã§Ã¶zmek ($[1,1]\to0$, $[1,0]\to1$). Bu lineer olmayan bir problemdir.
*   **Zorluk:** Gizli katman olmadan standart lineer aÄŸlar iÃ§in imkansÄ±zdÄ±r.
*   **SonuÃ§:** **Ã‡Ã¶zÃ¼ldÃ¼ (Loss 0.000000)**. RealNet, sÄ±nÄ±flarÄ± ayÄ±rmak iÃ§in uzay-zamanÄ± bÃ¼ker.
    <details>
    <summary>DoÄŸruluk Tablosunu GÃ¶r</summary>

    ```text
      A      B |   XOR (Tahmin)| MantÄ±k
    ----------------------------------------
      -1.0   -1.0 |      -1.0009 | 0 (OK)
      -1.0    1.0 |       1.0000 | 1 (OK)
       1.0   -1.0 |       1.0000 | 1 (OK)
       1.0    1.0 |      -1.0004 | 0 (OK)
    ```
    </details>
*   **Mimari:** **3 NÃ¶ron** (2 GiriÅŸ, 1 Ã‡Ä±kÄ±ÅŸ). **0 Gizli NÃ¶ron**. Toplam **9 Parametre**.
*   **DÃ¼ÅŸÃ¼nme SÃ¼resi:** **5 AdÄ±m**.
*   **Script:** `PoC/convergence_gates.py`
*   **Ä°Ã§gÃ¶rÃ¼:** RealNet **ZamanÄ± bir Gizli Katman** olarak kullanÄ±r. Girdiyi sadece 5 zaman adÄ±mÄ± Ã¼zerine katlayarak, kaotik olarak birbirine baÄŸlÄ± 3 nÃ¶ronun XOR problemini tek bir fiziksel katmanda Ã§Ã¶zebildiÄŸini kanÄ±tlar.

#### C. MNIST Maratonu (GÃ¶rsel Zeka)
RealNet'in gÃ¶rsel yetenekleri, saÄŸlamlÄ±k, Ã¶lÃ§eklenebilirlik ve verimliliÄŸi kanÄ±tlamak iÃ§in dÃ¶rt farklÄ± koÅŸulda test edildi.

**1. Ana Benchmark (Saf SÄ±fÄ±r-Gizli)**
*   **Hedef:** Tam 28x28 MNIST (784 Piksel).
*   **Mimari:** 794 NÃ¶ron (Girdi+Ã‡Ä±ktÄ±). **0 Gizli Katman.**
*   **SonuÃ§:** **%95.3 - %96.2 DoÄŸruluk**.
    <details>
    <summary>EÄŸitim Logunu GÃ¶r</summary>

    ```text
    Epoch 100: Loss 0.1012 | Test Acc 95.30%
    (Tarihi En Ä°yi: Epoch 69'da %96.2)
    ```
    </details>
*   **Script:** `PoC/convergence_mnist.py`
*   **Ä°Ã§gÃ¶rÃ¼:** Standart lineer modeller ~%92'de tÄ±kanÄ±r. RealNet, Derin Ã–ÄŸrenme katmanlarÄ± olmadan, sadece **Zamansal Derinlik** sayesinde Derin Ã–ÄŸrenme performansÄ± (~%96) yakalar.

**2. Darwin Deneyi (En GÃ¼Ã§lÃ¼nÃ¼n Hayatta KalmasÄ±)**
*   **YÃ¶ntem:** MNIST eÄŸitilirken her epoch sonunda zayÄ±f baÄŸlantÄ±larÄ± **budamak (pruning)**.
*   **SonuÃ§:** **%93.6 Ã–lÃ¼ Sinaps** ile **%94.2 DoÄŸruluk**.
    <details>
    <summary>Hayatta Kalma Ä°statistiklerini GÃ¶r</summary>

    ```text
    Ã–lÃ¼ Sinapslar: 93.59% (590054/630436)
    Aktif Parametre: ~40k
    DoÄŸruluk: 94.20%
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_mnist_alive.py`
*   **Ä°Ã§gÃ¶rÃ¼:** RealNet organiktir. Kendini bÃ¼yÃ¼tÃ¼r ve budar, yÃ¼ksek zekayÄ± korurken enerji verimliliÄŸini optimize eder.

**3. Anka KuÅŸu Deneyi (SÃ¼rekli Rejenerasyon)**
*   **Hipotez:** Ã–lÃ¼ sinapslarÄ± sadece Ã¶ldÃ¼rmek yerine **yeniden canlandÄ±rarak** (rastgele yeniden baÅŸlatma) %100 parametre verimliliÄŸine ulaÅŸabilir miyiz?
*   **SonuÃ§:** **%95.2 DoÄŸruluk**.
*   **GÃ¶zlemler:**
    *   Epoch 1: AÄŸÄ±n **%22'si** "iÅŸe yaramaz" kabul edildi ve yeniden doÄŸdu.
    *   Epoch 50: Yeniden doÄŸuÅŸ oranÄ± **%0.26'ya** dÃ¼ÅŸtÃ¼.
    *   DoÄŸruluk, bu sÃ¼rekli cerrahi operasyon sÄ±rasÄ±nda %50'den **%95.2'ye** tÄ±rmandÄ±.
    <details>
    <summary>Rejenerasyon Logunu GÃ¶r</summary>

    ```text
    Epoch 1: Acc 50.90% | Revived: 22.05% (Kitlesel Yok OluÅŸ)
    Epoch 5: Acc 87.50% | Revived: 1.13% (Stabilizasyon)
    Epoch 50: Acc 95.20% | Revived: 0.26% (Metabolik Denge)
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_mnist_revive.py`
*   **Ä°Ã§gÃ¶rÃ¼:** Kapasiteyi kÃ¼Ã§Ã¼lten standart budamanÄ±n aksine, RealNet zayÄ±f baÄŸlantÄ±larÄ± sÃ¼rekli geri dÃ¶nÃ¼ÅŸtÃ¼rerek tam kapasiteyi koruyabilir. Bu, doygunluk olmadan **SÃ¼rekli Ã–ÄŸrenmeyi** (FineWeb'deki gibi) mÃ¼mkÃ¼n kÄ±lar. "Hata, Ã–zellik Oldu (Bug became a Feature)."

**4. Tiny Challenge (AÅŸÄ±rÄ± KÄ±sÄ±tlamalar)**
*   **Hedef:** 7x7 KÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ MNIST. (Bir ikondan bile kÃ¼Ã§Ã¼k).
*   **Mimari:** **59 NÃ¶ron** toplam (~3.5k Parametre).
*   **SonuÃ§:** **~%89.3 DoÄŸruluk**.
    <details>
    <summary>Tiny SonuÃ§larÄ±nÄ± GÃ¶r</summary>

    ```text
    Epoch 50: Loss 0.1107 | Test Acc 89.30%
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_mnist_tiny.py`
*   **Ä°Ã§gÃ¶rÃ¼:** Bir "Bootloader"dan daha az kod/parametre ile bile sistem saÄŸlam Ã¶zellikler Ã¶ÄŸrenebilir.

**4. Scaled Test (Orta Ã–lÃ§ekli)**
*   **Hedef:** 14x14 KÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ MNIST.
*   **Mimari:** ~42k Parametre.
*   **SonuÃ§:** **%91.2 DoÄŸruluk**.
    <details>
    <summary>Scaled SonuÃ§larÄ±nÄ± GÃ¶r</summary>

    ```text
    Epoch 20: Loss 0.1413 | Test Acc 91.20%
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_mnist_scaled.py`

#### E. SinÃ¼s DalgasÄ± Ãœreteci (Dinamik Rezonans)
*   **Hedef:** $t=0$ anÄ±ndaki tek bir girdi deÄŸeriyle kontrol edilen frekanssa sinÃ¼s dalgasÄ± Ã¼retmek.
*   **Zorluk:** AÄŸ, bir **Voltaj KontrollÃ¼ OsilatÃ¶r (VCO)** gibi davranmalÄ±dÄ±r. Statik bir bÃ¼yÃ¼klÃ¼ÄŸÃ¼ dinamik bir zamansal periyoda dÃ¶nÃ¼ÅŸtÃ¼rmelidir.
*   **SonuÃ§:** **MÃ¼kemmel Osilasyon**. AÄŸ 30+ adÄ±m boyunca pÃ¼rÃ¼zsÃ¼z sinÃ¼s dalgalarÄ± Ã¼retir.
    <details>
    <summary>Frekans KontrolÃ¼nÃ¼ GÃ¶r</summary>

    ```text
    Frekans 0.15 (YavaÅŸ Dalga):
      t=1:  Hedef 0.1494 | RealNet 0.2871
      t=11: Hedef 0.9969 | RealNet 0.9985 (Tepe Senk.)
      t=26: Hedef -0.6878 | RealNet -0.6711
    
    Frekans 0.45 (HÄ±zlÄ± Dalga):
      t=1:  Hedef 0.4350 | RealNet 0.1783
      t=26: Hedef -0.7620 | RealNet -0.7826
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_sine_wave.py`
*   **Ä°Ã§gÃ¶rÃ¼:** RealNet **Programlanabilir bir OsilatÃ¶rdÃ¼r**. Bu, tek bir tohumdan (seed) sonsuz sayÄ±da benzersiz zamansal yÃ¶rÃ¼nge Ã¼retebileceÄŸini doÄŸrular.

#### F. Gecikmeli ToplayÄ±cÄ± (Bellek ve MantÄ±k)
*   **Hedef:** Girdi A ($t=2$), Girdi B ($t=8$). Ã‡Ä±ktÄ± A+B ($t=14$).
*   **Zorluk:** RealNet, A'yÄ± 6 adÄ±m boyunca "aklÄ±nda tutmalÄ±", sessizliÄŸi yok saymalÄ±, B'yi almalÄ± ve toplamÄ± hesaplamalÄ±dÄ±r.
*   **SonuÃ§:** **MSE KaybÄ±: ~0.01**.
    <details>
    <summary>"AkÄ±ldan Matematik" SonuÃ§larÄ±nÄ± GÃ¶r</summary>

    ```text
    -0.3 + 0.1 = -0.20 | RealNet: -0.2271 (Fark: 0.02)
     0.5 + 0.2 =  0.70 | RealNet:  0.4761 (Fark: 0.22 - YÃ¼ksek genlikte zorlanma)
     0.1 + -0.1 = 0.00 | RealNet: -0.0733 (Fark: 0.07)
    -0.4 + -0.4 = -0.80 | RealNet: -0.7397 (Fark: 0.06)
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_adder.py`
*   **Ä°Ã§gÃ¶rÃ¼:** **KÄ±sa SÃ¼reli BelleÄŸi** doÄŸrular. AÄŸ, $A$ deÄŸiÅŸkenini kaotik durumunda tutar, $B$'yi bekler ve toplamÄ± Ã¼retmek iÃ§in lineer olmayan bir entegrasyon (yaklaÅŸÄ±k aritmetik) gerÃ§ekleÅŸtirir. Bu, RealNet'in sadece statik fotoÄŸraflarÄ± deÄŸil, **Video benzeri** veri akÄ±ÅŸlarÄ±nÄ± da iÅŸleyebildiÄŸini gÃ¶sterir. "AkÄ±ldan Matematik" yapmaya benzer.

#### G. MÃ¼hÃ¼r (The Latch) - Ä°rade Testi
*   **Hedef:** Bir tetikleyici darbe bekle. AlÄ±ndÄ±ÄŸÄ±nda, Ã§Ä±ktÄ±yÄ± "AÃ‡IK" duruma getir ve **sonsuza kadar tut**.
*   **Zorluk:** Standart RNN'ler zamanla sÃ¶nÃ¼mlenir (unutur). RealNet enerjiyi kararlÄ± bir Ã§ekicide (attractor) hapsetmelidir.
*   **SonuÃ§:** **MÃ¼kemmel KararlÄ±lÄ±k**. Tetiklendikten sonra karar sÃ¼resiz korunur.
    <details>
    <summary>"Ä°rade" Logunu GÃ¶r</summary>

    ```text
    Tetik gÃ¶nderildi t=5
    t=04 | Out: 0.0674 | KAPALI ğŸ”´
    t=05 | Out: 0.0531 | KAPALI âš¡ TETÄ°K!
    t=06 | Out: 0.8558 | AÃ‡IK   ğŸŸ¢
    ...
    t=19 | Out: 0.9033 | AÃ‡IK   ğŸŸ¢ (Hala sÄ±msÄ±kÄ± tutuyor)
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_latch.py`
*   **Ä°Ã§gÃ¶rÃ¼:** **Karar SÃ¼rdÃ¼rme (Decision Maintaining)** yeteneÄŸini gÃ¶sterir. RealNet bir seÃ§im yapabilir ve Ã§Ã¼rÃ¼meye direnerek bu kararÄ±nda Ä±srar edebilir.

#### H. Kronometre (The Stopwatch) - Ä°Ã§sel Saat
*   **Hedef:** "X adÄ±m bekle, sonra ateÅŸle." (Bekleme sÄ±rasÄ±nda dÄ±ÅŸarÄ±dan hiÃ§bir veri gelmez).
*   **Zorluk:** AÄŸ, dÄ±ÅŸ bir saat olmadan zamanÄ± kendi iÃ§inde saymalÄ±dÄ±r.
*   **SonuÃ§:** **MSE KaybÄ±: ~0.01**. Hassas zamanlama baÅŸarÄ±ldÄ± (Hata: 0).
    <details>
    <summary>"Ritim" Ã‡Ä±ktÄ±sÄ±nÄ± GÃ¶r</summary>

    ```text
    Hedef SÃ¼re: 10 adÄ±m (Girdi 0.5)
    t=09 | Out: 0.5178 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    t=10 | Out: 0.8029 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ¯ HEDEF (Tam isabet!)
    t=11 | Out: 0.3463 â–ˆâ–ˆâ–ˆ

    Hedef SÃ¼re: 20 adÄ±m (Girdi 1.0)
    t=18 | Out: 0.2001 â–ˆâ–ˆ
    t=19 | Out: 0.6574 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    t=20 | Out: 0.6726 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ğŸ¯ HEDEF
    t=21 | Out: 0.2092 â–ˆâ–ˆ
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_stopwatch.py`
*   **Ä°Ã§gÃ¶rÃ¼:** **Ritim ve Zaman AlgÄ±sÄ±**. RealNet sadece veriyi iÅŸlemez; zamanÄ± *deneyimler*.

#### I. DÃ¼ÅŸÃ¼nen Dedektif (The Thinking Detective) - BaÄŸlam ve AkÄ±l YÃ¼rÃ¼tme
*   **Hedef:** Bir 0 ve 1 akÄ±ÅŸÄ±nÄ± izle. **SADECE** `1-1` deseni oluÅŸtuÄŸunda alarm ver.
*   **Kritik DokunuÅŸ:** AÄŸa her bitten sonra "DÃ¼ÅŸÃ¼nmesi" iÃ§in 3 adÄ±mlÄ±k "Sessizlik" verdik.
*   **SonuÃ§:** **Kusursuz Tespit**.
    <details>
    <summary>"Eureka!" AnÄ±nÄ± GÃ¶rmek Ä°Ã§in TÄ±kla</summary>

    ```text
    Zaman | Girdi | Ã‡Ä±ktÄ±    | Durum
    ----------------------------------------
    12    | 1     | -0.0235  |
    13    | .     | 0.0471   | (DÃ¼ÅŸÃ¼nÃ¼yor...)
    14    | .     | -0.0050  | (DÃ¼ÅŸÃ¼nÃ¼yor...)
    15    | .     | -0.0154  | (DÃ¼ÅŸÃ¼nÃ¼yor...)
    16    | 1     | 0.4884   | AteÅŸlemeli
    17    | .     | 1.0317 ğŸš¨ | (DÃ¼ÅŸÃ¼nme AdÄ±mÄ± 1 - EUREKA!)
    18    | .     | 1.0134 ğŸš¨ | (DÃ¼ÅŸÃ¼nme AdÄ±mÄ± 2)
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_detective_thinking.py`
*   **Ä°Ã§gÃ¶rÃ¼:** **ZekanÄ±n Zamana Ä°htiyaÃ§ DuyduÄŸunu** kanÄ±tlar. Sessiz adÄ±mlar sÄ±rasÄ±nda bilgiyi "sindirmesine" izin verildiÄŸinde, RealNet tamamen reaktif aÄŸlarÄ±n yapamadÄ±ÄŸÄ± karmaÅŸÄ±k zamansal mantÄ±ÄŸÄ± (Zaman Ãœzerinden XOR) Ã§Ã¶zer.

#### J. KÃ¼tÃ¼phaneci (NÃ¶ral VeritabanÄ±)
*   **Hedef:** Oku-Yaz HafÄ±za gibi davranmak. `YAZ K1=0.5`. Bekle... `OKU K1`. Ã‡Ä±ktÄ±: `0.5`.
*   **Zorluk:** AÄŸÄ±n, kaotik gizli durumunda birden Ã§ok anahtar-deÄŸer Ã§iftini birbirine karÄ±ÅŸtÄ±rmadan saklamasÄ± ve istendiÄŸinde geri Ã§aÄŸÄ±rmasÄ± gerekir. Bu, **Ã–rtÃ¼lÃ¼ Dikkat** gerektirir.
*   **SonuÃ§:** **~%92 DoÄŸruluk** (4 Anahtar, 1024 NÃ¶ron ile).
    <details>
    <summary>HafÄ±za EriÅŸim Logunu GÃ¶r</summary>

    ```text
    AdÄ±m  | Komut    | Key   | DeÄŸer    | Hedef    | RealNet  | Durum
    -------------------------------------------------------------------
    0     | YAZ      | K0    | 0.4426   | 0.4426   | 0.0208   | âš™ï¸
    ...   | (HafÄ±za PekiÅŸtiriliyor...)
    12    | (4)      | ...   |          | 0.4426   | 0.4602   | âœ… KAYDEDÄ°LDÄ°
    ...   | (20 Saniye Bekle...)
    32    | OKU      | K0    | 0.0000   | 0.4426   | 0.4506   | âœ… HATIRLANDI
    48    | SÄ°L      | K0    | 0.0000   | 0.0000   | 0.0117   | âœ… SÄ°LÄ°NDÄ°
    ```
    </details>
*   **Script:** `PoC/experiments/convergence_realnet_as_database.py`
*   **Ä°Ã§gÃ¶rÃ¼:** RealNet'in **Anahtar-DeÄŸer Dikkati (Attention)** mekanizmalarÄ±nÄ± tamamen dinamikler yoluyla simÃ¼le edebileceÄŸini kanÄ±tlar. `GELU` ve yÃ¼ksek `Israr (Persistence)` (0.5) kullanarak, sorgu sinyaliyle adreslenebilen kararlÄ± "hafÄ±za kuyularÄ±" oluÅŸturur; bÃ¶ylece aÃ§Ä±k saklama matrisleri olmadan Transformer'Ä±n KV Cache iÅŸini yapar.

#### ğŸ”® Vizyon: Silikonun Ruhu (RealNet-1B)
RealNet, yapay zekanÄ±n fabrika modeline karÅŸÄ± bir isyandÄ±r. ZekanÄ±n mekanik bir katman yÄ±ÄŸÄ±nÄ± deÄŸil, **sinyallerin organik yankÄ±lanmasÄ±** olduÄŸuna inanÄ±yoruz.

UzayÄ± feda edip ZamanÄ± kullanarak gÃ¶rsel problemleri SÄ±fÄ±r Gizli Katman ile Ã§Ã¶zebiliyorsak, bu yaklaÅŸÄ±m dil modellerine de uyarlanabilir.

*   **Hipotez:** 1 Milyar parametreli bir model (RealNet-1B), daha fazla adÄ±m "dÃ¼ÅŸÃ¼nerek" Ã§ok daha bÃ¼yÃ¼k modellerin (Ã¶rneÄŸin Llama-70B) akÄ±l yÃ¼rÃ¼tme derinliÄŸine ulaÅŸabilir.
*   **Hedef:** Ev kullanÄ±cÄ±sÄ± donanÄ±mÄ±nda (Ã¶rneÄŸin RTX 3060) verimli ve yÃ¼ksek muhakeme yeteneÄŸine sahip Yapay Zeka.

> "Petabaytlarca VRAM'e ihtiyacÄ±mÄ±z yok. Sadece Zamana ihtiyacÄ±mÄ±z var."

Zaman tanÄ±ndÄ±ÄŸÄ±nda "dÃ¼ÅŸÃ¼nebilen" ve "nefes alabilen" kaotik bir nÃ¶ron ormanÄ±nÄ±n, devasa endÃ¼striyel fabrikalarÄ± yenebileceÄŸini kanÄ±tladÄ±k. MekanÄ± Zamanla takas ederek Ruhu buluyoruz.

---

## ğŸ‘¨â€ğŸ’» Yazar (Author)

**Cahit Karahan**
*   DoÄŸum: 12/02/1997, Ankara.
*   "Kaosun MimarÄ±."

---

## LÄ°SANS

MIT
