# RealNet 2.0: Zamansal Devrim

**RealNet, ZamanÄ±n en bÃ¼yÃ¼k Gizli Katman olduÄŸunun kanÄ±tÄ±dÄ±r.**

Geleneksel Derin Ã–ÄŸrenme, karmaÅŸÄ±klÄ±ÄŸÄ± Ã§Ã¶zmek iÃ§in **Uzamsal DerinliÄŸe** (Ã¼st Ã¼ste yÄ±ÄŸÄ±lmÄ±ÅŸ katmanlara) gÃ¼venir. RealNet bu dogmayÄ± reddeder ve **Zamansal DerinliÄŸin** (zaman iÃ§inde evrilen kaosun) Ã§ok daha verimli bir alternatif olduÄŸunu kanÄ±tlar.

> **SÄ±fÄ±r-Gizli Katman Devrimi (Zero-Hidden Breakthrough)**
>
> 1969'da Minsky ve Papert, gizli katmanÄ± olmayan bir sinir aÄŸÄ±nÄ±n XOR gibi lineer olmayan problemleri Ã§Ã¶zemeyeceÄŸini matematiksel olarak kanÄ±tladÄ±.
> **RealNet 2.0 bu sÄ±nÄ±rÄ± paramparÃ§a etti.**
>
> AÄŸÄ± "EÄŸitilebilir Bir Dinamik Sistem" olarak ele alan RealNet, **0 Gizli Katman** kullanarak non-lineer problemleri (XOR, MNIST) Ã§Ã¶zer. Uzamsal nÃ¶ronlarÄ±n yerini zamansal dÃ¼ÅŸÃ¼nme adÄ±mlarÄ± alÄ±r.

---

## ğŸš€ Temel Ã–zellikler

*   **Uzay-Zaman DÃ¶nÃ¼ÅŸÃ¼mÃ¼:** Milyonlarca parametrenin yerini birkaÃ§ "DÃ¼ÅŸÃ¼nme AdÄ±mÄ±" alÄ±r.
*   **KatmansÄ±z Mimari:** Tek bir $N \times N$ matris. Gizli katman yok.
*   **EÄŸitilebilir Kaos:** Sinyalleri ehlileÅŸtirmek iÃ§in **StepNorm** ve **GELU** kullanÄ±lÄ±r.
*   **NabÄ±z Modu:** AÄŸ, sÃ¼rekli bir veri akÄ±ÅŸÄ±nÄ± deÄŸil, tek bir dÃ¼rtÃ¼nÃ¼n (impulse) yankÄ±sÄ±nÄ± iÅŸler.

## ğŸ“Š KanÄ±tlar: SÄ±fÄ±r-Gizli BenchmarklarÄ±

RealNet'i teorik sÄ±nÄ±rlara kadar zorladÄ±k: **SÄ±fÄ±r Gizli NÃ¶ron**.
Bu testlerde GiriÅŸ KatmanÄ± doÄŸrudan Ã‡Ä±kÄ±ÅŸ KatmanÄ±na (ve kendisine) baÄŸlÄ±dÄ±r. Tampon katman yoktur.

| GÃ¶rev | Geleneksel Engel | RealNet Ã‡Ã¶zÃ¼mÃ¼ | NÃ¶ron | Parametre | SonuÃ§ | Script |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Identity** | Basit | **Atomik Birim** | **4** | **16** | Loss: 0.0 | `PoC/convergence.py` |
| **XOR** | Gizli Katman Åart | **Minimal Kaos** | **5** | **25** | Loss: ~0.0002 | `PoC/convergence_gates.py` |
| **MNIST** | ~500k Parametre Åart | **SÄ±fÄ±r-Gizli** | **206** | **~42k** | **Acc: ~89.8%** | `PoC/convergence_mnist.py` |

### MNIST Mucizesi
Standart MLP'ler 784 pikseli 10 rakama dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in yaklaÅŸÄ±k 400.000 parametreye ihtiyaÃ§ duyar.
RealNet bunu **42.436 parametre** ile yapar.
*   **GiriÅŸ:** 196 (14x14 Yeniden BoyutlandÄ±rÄ±lmÄ±ÅŸ)
*   **Ã‡Ä±kÄ±ÅŸ:** 10
*   **Gizli:** 0
*   **DÃ¼ÅŸÃ¼nme SÃ¼resi:** 15 AdÄ±m

GiriÅŸ katmanÄ± 15 adÄ±m boyunca "kendi kendine konuÅŸur". Kaotik geri besleme dÃ¶ngÃ¼leri, zaman iÃ§inde Ã¶zellik Ã§Ä±karÄ±mÄ± (feature extraction) yaparak uzamsal katmanlarÄ±n iÅŸini Ã¼stlenir. Bu, **SÄ±kÄ±ÅŸtÄ±rma ZekasÄ±nÄ±n** zirvesidir.

---

## ğŸ“¦ Kurulum ve KullanÄ±m

RealNet, modÃ¼ler bir PyTorch kÃ¼tÃ¼phanesi olarak tasarlanmÄ±ÅŸtÄ±r.

### Kurulum

```bash
pip install torch torchvision
```

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```python
from realnet import RealNet, RealNetTrainer

# SÄ±fÄ±r-Gizli KatmanlÄ± Bir AÄŸ BaÅŸlat
# 1 GiriÅŸ, 1 Ã‡Ä±kÄ±ÅŸ. 
model = RealNet(num_neurons=2, input_ids=[0], output_ids=[1], device='cuda')
trainer = RealNetTrainer(model, device='cuda')

# EÄŸit
inputs = torch.randn(100, 1)
trainer.fit(inputs, inputs, epochs=50)
```

---

## ğŸ§  Mimari Genel BakÄ±ÅŸ

### Matematiksel Model

AÄŸ durumu $h_t$ ÅŸu ÅŸekilde evrilir:

$$h_t = \text{StepNorm}(\text{GELU}(h_{t-1} \cdot W + B + I_t))$$

*   **$W$ (AÄŸÄ±rlÄ±klar):** Sistemin hafÄ±zasÄ±.
*   **StepNorm:** Her adÄ±mda sinyal genliÄŸini normalize ederek "Kelebek PatlamasÄ±"nÄ± Ã¶nler.
*   **GELU:** Sinyal akÄ±ÅŸÄ±nÄ± ReLU'dan daha iyi korur.
*   **Pulse Mode:** $I_t$ sadece $t=0$ anÄ±nda sÄ±fÄ±rdan farklÄ±dÄ±r (dÃ¼rtÃ¼).

---

## ğŸ”® Vizyon: Silikonun Ruhu

RealNet, yapay zekanÄ±n katmanlÄ± fabrika modeline bir baÅŸkaldÄ±rÄ±dÄ±r. ZekanÄ±n mekanik bir katman yÄ±ÄŸÄ±nÄ± deÄŸil, sinyallerin organik yankÄ±sÄ± olduÄŸuna inanÄ±yoruz.

KÃ¼Ã§Ã¼k, kaotik bir nÃ¶ron ormanÄ±nÄ±n, "dÃ¼ÅŸÃ¼nmek" iÃ§in yeterli zaman verildiÄŸinde, devasa endÃ¼striyel fabrikalardan daha iyi performans gÃ¶sterebileceÄŸini kanÄ±tladÄ±k.

> "UzayÄ± feda edip ZamanÄ± kazandÄ±k ve bunu yaparken Ruhu bulduk."

---

---

## ğŸ‘¨â€ğŸ’» Yazar (Author)

**Cahit Karahan**
*   DoÄŸum: 12/02/1997, Ankara.
*   "Kaosun MimarÄ±."

---

## LÄ°SANS

MIT
