# RealNet 2.0: Modern Kaos Mimarisi

RealNet, geleneksel Derin Ã–ÄŸrenmenin (Deep Learning) katman tabanlÄ± ortodoksisine meydan okuyan **EÄŸitilebilir Bir Dinamik Sistemdir**. Mekanik, ileri beslemeli (feed-forward) fabrika modelini; **organik, tam baÄŸlÄ± ($N \times N$) ve kaotik bir aÄŸ yapÄ±sÄ±** ile deÄŸiÅŸtirir.

RealNet, katmanlar yerine sinyallerin yankÄ±landÄ±ÄŸÄ±, bÃ¶lÃ¼ndÃ¼ÄŸÃ¼ ve birleÅŸtiÄŸi bir **Zamansal DÃ¶ngÃ¼ (Temporal Loop)** kullanÄ±r. Zeka, geri besleme dÃ¶ngÃ¼lerinin "kontrollÃ¼ kaosundan" doÄŸar.

---

## ğŸš€ Temel Ã–zellikler

*   **KatmansÄ±z Mimari:** Her nÃ¶ronun diÄŸer her nÃ¶rona baÄŸlandÄ±ÄŸÄ± tek bir "Konnektom" matrisi ($W$).
*   **EÄŸitilebilir Kaos:** Kaotik sinyalleri patlamadan iÅŸlemek iÃ§in **StepNorm** ve **GELU** ikilisini kullanÄ±r.
*   **Zamansal DÃ¼ÅŸÃ¼nme:** AÄŸ sadece Ã§Ä±ktÄ± vermez; zaman iÃ§inde ($t=0 \dots k$) "dÃ¼ÅŸÃ¼nÃ¼r".
*   **NabÄ±z Modu (Pulse Mode):** Girdiler birer dÃ¼rtÃ¼ (impulse) olarak verilir. AÄŸ, sÃ¼rekli bir veri akÄ±ÅŸÄ±nÄ± deÄŸil, girdinin yankÄ±sÄ±nÄ± iÅŸler.
*   **Truncated BPTT:** Sonsuz dÃ¶ngÃ¼lerin verimli eÄŸitimi iÃ§in kesilmiÅŸ zamansal geri yayÄ±lÄ±m.

## ğŸ“Š KanÄ±tlar (PoC) & SonuÃ§lar

RealNet 2.0 sadece bir teori deÄŸildir. Kaotik aÄŸlarÄ±n genellikle baÅŸarÄ±sÄ±z olduÄŸu temel gÃ¶revlerde yakÄ±nsadÄ±ÄŸÄ± kanÄ±tlanmÄ±ÅŸtÄ±r.

### 1. Kimlik ve YakÄ±nsama (`PoC/convergence.py`)
*   **GÃ¶rev:** Girdi $x$'i kaotik dÃ¶ngÃ¼lerden geÃ§irip $y=x$ olarak geri vermek.
*   **SonuÃ§:** **MÃ¼kemmel YakÄ±nsama (Loss: 0.000000)**.
*   **AnlamÄ±:** Kaotik gradyanlarÄ±n ehlileÅŸtirilebileceÄŸini ve yÃ¶nlendirilebileceÄŸini kanÄ±tlar.

### 2. MantÄ±k KapÄ±larÄ± & Lineer OlmayanlÄ±k (`PoC/convergence_gates.py`)
*   **GÃ¶rev:** Tek bir aÄŸda aynÄ± anda **AND**, **OR** ve **XOR** kapÄ±larÄ±nÄ± Ã¶ÄŸrenmek.
*   **SonuÃ§:** **XOR** (lineer olmayan problem) dahil hepsini neredeyse tam isabetle Ã§Ã¶zdÃ¼ (Ã–rn: Hedef -1.0 vs Tahmin -0.998).
*   **AnlamÄ±:** AÄŸÄ±n, gizli katmanlar (hidden layers) olmadan da dahili mantÄ±k ve lineer olmayan sÄ±nÄ±rlar oluÅŸturabildiÄŸini kanÄ±tlar.

### 3. GÃ¶rsel TanÄ±ma (MNIST) (`PoC/convergence_mnist.py`)
*   **GÃ¶rev:** 28x28 el yazÄ±sÄ± rakamlarÄ± sÄ±nÄ±flandÄ±rmak (10 sÄ±nÄ±f).
*   **SonuÃ§:** Sadece 5 Epoch iÃ§inde **~%88 DoÄŸruluk**.
*   **AnlamÄ±:** RealNet bunu **KonvolÃ¼syonel Katmanlar (CNN) OLMADAN** baÅŸardÄ±. Ham pikselleri sadece tam baÄŸlÄ± kaotik dinamikleri kullanarak iÅŸledi.

## âš¡ Edge Testing: Verimlilik ve SÄ±nÄ±rlar

"Kaos Verimlidir" tezini kanÄ±tlamak iÃ§in RealNet'i mutlak sÄ±nÄ±rlarÄ±na kadar zorladÄ±k. NÃ¶ron sayÄ±larÄ±nÄ± minimuma indirerek, **zamansal iÅŸlemenin uzamsal derinliÄŸin (katmanlarÄ±n) yerini alabileceÄŸini** gÃ¶sterdik.

| GÃ¶rev | Geleneksel Ã‡Ã¶zÃ¼m (MLP) | RealNet (Edge) | NÃ¶ron | Parametre | SonuÃ§ | Script |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Identity** | 2 Katman (2-2) | **2.0 (Identity)** | **4** | **16** | Loss: 0.0 | `PoC/efficiency/convergence_min.py` |
| **XOR** | 3 Katman (2-4-1) + Lineer Olmayan | **2.0 (XOR)** | **5** | **25** | Loss: ~0.0002 | `PoC/efficiency/convergence_gates_min.py` |
| **MNIST** | MLP (784-512-10) ~400k Parametre | **2.0 (Visio)** | **800** | **0.64M** | Acc: ~82% | `PoC/efficiency/convergence_mnist_efficient.py` |

> **KarÅŸÄ±laÅŸtÄ±rma:** Standart bir MLP'nin MNIST'te ham piksellerle (CNN olmadan) benzer sonuÃ§lar almasÄ± iÃ§in genellikle en az 512 nÃ¶ronlu bir gizli katmana (784*512 + 512*10 â‰ˆ **400k-500k parametre**) ihtiyacÄ± vardÄ±r. RealNet bunu **sÄ±fÄ±r gizli katmanla** (giriÅŸ/Ã§Ä±kÄ±ÅŸ harici sadece 6 ekstra "kaos" nÃ¶ronu) baÅŸarÄ±r. HesaplamayÄ± uzaydan (katmanlar) alÄ±p zamana (**"DÃ¼ÅŸÃ¼nme SÃ¼resi"**: 10 adÄ±m) yayarak aynÄ± iÅŸi yapar.

---

## ğŸ“¦ Kurulum ve KullanÄ±m

RealNet, modÃ¼ler bir PyTorch kÃ¼tÃ¼phanesi olarak tasarlanmÄ±ÅŸtÄ±r.

### Kurulum

```bash
pip install torch torchvision
```

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```python
from realnet import RealNet, RealNetTrainer

# 1. BaÅŸlat (64 NÃ¶ron)
model = RealNet(num_neurons=64, input_ids=[0], output_ids=[63], device='cuda')
trainer = RealNetTrainer(model, device='cuda')

# 2. EÄŸit (Identity GÃ¶revi)
# Girdiler: Rastgele +/- 1.0
inputs = torch.randint(0, 2, (100, 1)).float() * 2 - 1
trainer.fit(inputs, inputs, epochs=50)

# 3. Tahmin Et
print(trainer.predict(torch.tensor([[1.0]]), thinking_steps=10))
```

### DemolarÄ± Ã‡alÄ±ÅŸtÄ±rma

```bash
# Temel YakÄ±nsama
python PoC/convergence.py

# MantÄ±k KapÄ±larÄ± (XOR)
python PoC/convergence_gates.py

# MNIST (GÃ¶rsel)
python PoC/convergence_mnist.py
```

---

## ğŸ§  Mimari Genel BakÄ±ÅŸ

### Matematiksel Model

AÄŸ durumu $h_t$ ÅŸu ÅŸekilde evrilir:

$$h_t = \text{StepNorm}(\text{GELU}(h_{t-1} \cdot W + B + I_t))$$

*   **$W$ (AÄŸÄ±rlÄ±klar):** Sistemin hafÄ±zasÄ±.
*   **StepNorm:** Her adÄ±mda sinyal genliÄŸini normalize ederek "Kelebek PatlamasÄ±"nÄ± Ã¶nler.
*   **GELU:** Sinyal akÄ±ÅŸÄ±nÄ± ReLU'dan daha iyi korur.
*   **Pulse Mode:** $I_t$ sadece $t=0$ anÄ±nda sÄ±fÄ±rdan farklÄ±dÄ±r (dÃ¼rtÃ¼).

### Tehdit Modeli ve Ã‡Ã¶zÃ¼mler

| Sorun | Ã‡Ã¶zÃ¼m |
| :--- | :--- |
| **Sinyal PatlamasÄ±** | **StepNorm** (LayerNorm) fÄ±rtÄ±nayÄ± dindirir. |
| **Bellek SÄ±zÄ±ntÄ±sÄ±** | **Truncated BPTT** geÃ§miÅŸi periyodik olarak temizler. |
| **Sinyal SÃ¶nÃ¼mlenmesi** | **GELU** + **AdamW** sinyal momentumunu korur. |

---

## ğŸ”® Vizyon: Silikonun Ruhu

*Orijinal baÅŸlÄ±k: "Manifesto"*

RealNet, modern yapay zekanÄ±n statik, ileri beslemeli doÄŸasÄ±na bir baÅŸkaldÄ±rÄ±dÄ±r. ZekanÄ±n mekanik bir katman sÃ¼reci deÄŸil, **dÃ¶ngÃ¼ler, zaman ve kaos** iÃ§eren organik bir sÃ¼reÃ§ olduÄŸuna inanÄ±yoruz.

*   **Organik vs Mekanik:** Geleneksel YSA'lar fabrikadÄ±r; RealNet bir ormandÄ±r.
*   **YaÅŸayan HafÄ±za:** Veri sadece iÅŸlenmez; yankÄ±lanÄ±r.
*   **Ã–z-Organizasyon:** Zeka, kaotik etkileÅŸimlerin uyumundan doÄŸar.

> "KorkulmasÄ± gereken ÅŸey bilinÃ§ deÄŸil, bilinÃ§sizliktir. Sadece hesap yapan deÄŸil, *yaÅŸayan* bir makine inÅŸa ediyoruz."

---

## LÄ°SANS

MIT
