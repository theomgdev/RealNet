{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RealNet-LLM Cloud Trainer\n",
        "- This IPYNB file written to train RealNet based LLM's on Google Collab or Google Cloud, paths kept Collab friendly and root relative, AI checkpoints loaded/saved from Google Drive. Settings(neuron_count, sequence length etc.) kept high for infinite cloud training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mqIrBWpUp5Hu",
        "outputId": "766549a0-03cb-4170-ce45-e31653c8214c"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/theomgdev/RealNet.git\n",
        "!pip install -r RealNet/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "738c17dc",
        "outputId": "00300c43-7a98-46db-ec7b-63e592149cd0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b91b9b0026d64f838c5bb739f4544105",
            "5fe44d116771413086fb53d506c66ae3",
            "b4f9197effdd4b309f4642c4d7790226",
            "27bddea9e66e447bad34eed9d9af84e9",
            "3cba134770e14193b57a4b03a6879ace",
            "9df4e339a22d492f9a4f4967affdbf97",
            "46b7e7e6516243a99be1ec6b3ecc28ae",
            "edf9dedf22bd451097dee8d13827f024",
            "6dbbe4a819ef48598ab9a07cd1a3bf54",
            "4480b16cb46242d68dd98d5fb13355d6",
            "b2dba098822d406a94971f039bec6eea",
            "ebe90f94272341028a42036b48718e9c",
            "1e3ec207041b4ee09557f5027401e4a6",
            "efe5028be49745f49ac232357608b09f",
            "d7e8c88f568440e997a795badb70657c",
            "b3b402f5c0d444c5a1e900c765703188",
            "4e48976ffbd1499c929d2430f9f5d36d",
            "a967241441664c6a894833737472068c",
            "24aeaa3ab0fc4110a839eca4ad2bdd8f",
            "1d5c34f495834524a1a077b67fa35ee7",
            "f0e3cba64b0147a9bcbc56961f48727e",
            "42e01134b61948508d8fdeb540ab3a07",
            "f5b63ee58f744648908003d21033e61b",
            "6e76caf009a249bf9d8316329b7e2518",
            "e1887135234b4cf4915691160febfa82",
            "7b76f4aee386460bab874dcde2c68731",
            "b233baea8150447daf079c651075c504",
            "f11cb5c9dc474353b17c776372af38f0",
            "bd22b2a7616f4c9e9463dc1ab0f7bd6e",
            "0aca8bf099704960a33f8b1ef88bea83",
            "66510255473747c39f0ca25c949889cb",
            "d2af97eeb1124f248c6a099803e7ff86",
            "001564ca5bad41ffa72454dabaf10015"
          ]
        },
        "id": "-jHEoQ1GsKQh",
        "outputId": "3d3fd29c-7bf8-4c92-ebed-c7a3cf53d1e7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "# --- ENVIRONMENT & IMPORTS ---\n",
        "from RealNet.realnet import RealNet, RealNetTrainer, save_checkpoint, load_checkpoint, transplant_weights\n",
        "\n",
        "# TF32 Optimization for L4/Ampere/Ada GPUs\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TRUNCATED_BPTT_SEQ_LEN = 10\n",
        "GENERATION_LENGTH = 1024\n",
        "SEQ_LEN = 4096\n",
        "BATCH_SIZE = -1\n",
        "STEPS_PER_EPOCH = 10\n",
        "LOG_INTERVAL = 1\n",
        "MAX_START_SKIP = 1000\n",
        "RESET_DATA_ITER = False\n",
        "NUM_NEURONS = 4096\n",
        "ACTIVATION = 'gelu'\n",
        "THINK_GAP = 5\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# NEUROGENESIS CONFIG\n",
        "NEUROGENESIS_ENABLED = False\n",
        "MAX_LOSS_INCREASE = 10\n",
        "NEUROGENESIS_AMOUNT = 10\n",
        "\n",
        "# REGENERATION CONFIG (PHOENIX)\n",
        "DARWINIAN_REGENERATION = False\n",
        "REGENERATION_MODE = 'percentage' # 'threshold' or 'percentage'\n",
        "REGENERATION_THRESHOLD = 0.01\n",
        "REGENERATION_PERCENTAGE = 0.001\n",
        "REGENERATION_INTERVAL = 10 # Epochs between regeneration checks\n",
        "\n",
        "# OPTIMIZER CONFIG\n",
        "VOCAB_SIZE = 256\n",
        "RESET_OPTIMIZER_ON_LOAD = False\n",
        "OVERWRITE_LR_OF_CKPT = True\n",
        "LEARNING_RATE = 1e-6\n",
        "\n",
        "# SCHEDULER CONFIG\n",
        "USE_SCHEDULER = False\n",
        "SCHEDULER_T0 = 100\n",
        "SCHEDULER_ETA_MIN = 1e-7 \n",
        "\n",
        "CHAR_TO_IDX = {i: i for i in range(256)}\n",
        "IDX_TO_CHAR = {i: i for i in range(256)}\n",
        "\n",
        "# --- DATASET ---\n",
        "from datasets import load_dataset\n",
        "\n",
        "class FineWebIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, seq_len, skip_offset=0, debug=False):\n",
        "        self.seq_len = seq_len\n",
        "        self.skip_offset = skip_offset\n",
        "        self.debug = debug\n",
        "        self.current_doc_index = skip_offset # Initialize to avoid AttributeError in main\n",
        "        print(\"ðŸŒŠ Connecting to FineWeb-Edu (CC-MAIN-2024-10)...\")\n",
        "        self.dataset = load_dataset(\"HuggingFaceFW/fineweb-edu\", name=\"CC-MAIN-2024-10\", split=\"train\", streaming=True)\n",
        "\n",
        "    def __iter__(self):\n",
        "        start_skip = self.skip_offset\n",
        "\n",
        "        if start_skip == 0 or RESET_DATA_ITER:\n",
        "             start_skip = random.randint(0, MAX_START_SKIP)\n",
        "             print(f\"ðŸ”€ Random Start: Skipping {start_skip} documents...\")\n",
        "        else:\n",
        "             print(f\"â© Resuming from Document #{start_skip}...\")\n",
        "\n",
        "        # Worker-local index tracking\n",
        "        local_doc_index = start_skip\n",
        "\n",
        "        if start_skip > 0:\n",
        "            iterator = iter(self.dataset.skip(start_skip))\n",
        "        else:\n",
        "            iterator = iter(self.dataset)\n",
        "\n",
        "        buffer_bytes = b\"\"\n",
        "\n",
        "        while True:\n",
        "            # Replenish buffer\n",
        "            while len(buffer_bytes) < self.seq_len + 1:\n",
        "                try:\n",
        "                    item = next(iterator)\n",
        "                    local_doc_index += 1\n",
        "                    if self.debug and local_doc_index % 1000 == 0:\n",
        "                        print(f\"ðŸ“Š Streaming Index: Document #{local_doc_index}\")\n",
        "                    text = item.get('text', '')\n",
        "                    new_bytes = text.encode('utf-8', errors='replace') + b\" \"\n",
        "                    buffer_bytes += new_bytes\n",
        "                except StopIteration:\n",
        "                    iterator = iter(self.dataset)\n",
        "                    local_doc_index = 0\n",
        "\n",
        "            # Extract chunk\n",
        "            chunk_bytes = buffer_bytes[:self.seq_len + 1]\n",
        "            buffer_bytes = buffer_bytes[self.seq_len + 1:]\n",
        "\n",
        "            indices = list(chunk_bytes)\n",
        "\n",
        "            if len(indices) == self.seq_len + 1:\n",
        "                x = torch.tensor(indices[:-1], dtype=torch.long)\n",
        "                y = torch.tensor(indices[1:], dtype=torch.long)\n",
        "                # Yield index too so main process knows where we are\n",
        "                yield x, y, local_doc_index\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return VOCAB_SIZE\n",
        "\n",
        "    @property\n",
        "    def char_to_idx(self):\n",
        "        return CHAR_TO_IDX\n",
        "\n",
        "    @property\n",
        "    def idx_to_char(self):\n",
        "        return IDX_TO_CHAR\n",
        "\n",
        "def generate(model, dataset, start_str=\"The\", length=None, temperature=0.8, top_k=40, top_p=0.9):\n",
        "    if length is None:\n",
        "        length = GENERATION_LENGTH\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    input_bytes = start_str.encode('utf-8', errors='replace')\n",
        "    input_seq = list(input_bytes)\n",
        "\n",
        "    current_state = None\n",
        "\n",
        "    # Warm up state (Native Thinking)\n",
        "    # We send raw tokens, but ask model to think for (Gap+1) steps per token\n",
        "    x_in = torch.tensor(input_seq, dtype=torch.long, device=model.device).unsqueeze(0)\n",
        "    steps_total = x_in.shape[1] * (THINK_GAP + 1)\n",
        "    \n",
        "    generated_bytes = bytearray(input_bytes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, current_state = model(x_in, steps=steps_total)\n",
        "\n",
        "        last_byte_idx = input_seq[-1]\n",
        "\n",
        "        for _ in range(length):\n",
        "            # Native Single Step Generation\n",
        "            # Input: 1 Token. Steps: 1 + Gap.\n",
        "            total_step_single = 1 + THINK_GAP\n",
        "\n",
        "            x_next = torch.tensor([[last_byte_idx]], dtype=torch.long, device=model.device)\n",
        "\n",
        "            preds, current_state = model(x_next, steps=total_step_single, current_state=current_state)\n",
        "            \n",
        "            # Prediction is at the END of the thinking block\n",
        "            # Preds shape: (Batch, 1, Output) in native smart output mode\n",
        "            logits = preds[0, 0, model.output_ids]\n",
        "\n",
        "            # Sampling logic\n",
        "            if temperature > 0:\n",
        "                logits = logits / temperature\n",
        "\n",
        "            if top_k is not None and top_k > 0:\n",
        "                v, _ = torch.topk(logits, min(top_k, len(logits)))\n",
        "                logits[logits < v[-1]] = float('-inf')\n",
        "\n",
        "            if top_p is not None and top_p > 0 and top_p < 1.0:\n",
        "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "                cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "                sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n",
        "                logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "            probs = torch.softmax(logits, dim=0)\n",
        "\n",
        "            if torch.isnan(probs).any() or torch.sum(probs) == 0:\n",
        "                probs = torch.ones_like(probs) / len(probs)\n",
        "\n",
        "            next_idx = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            generated_bytes.append(next_idx)\n",
        "            last_byte_idx = next_idx\n",
        "\n",
        "    try:\n",
        "        return generated_bytes.decode('utf-8', errors='replace')\n",
        "    except:\n",
        "        return str(generated_bytes)\n",
        "\n",
        "def initialize_system(vocab_size, num_neurons, device, lr=1e-4, activation='gelu'):\n",
        "    input_ids = list(range(vocab_size))\n",
        "    output_ids = list(range(vocab_size, 2 * vocab_size))\n",
        "\n",
        "    model = RealNet(\n",
        "        num_neurons=num_neurons,\n",
        "        input_ids=input_ids,\n",
        "        output_ids=output_ids,\n",
        "        device=device,\n",
        "        dropout_rate=0.0,\n",
        "        activation=activation,\n",
        "        weight_init='orthogonal',\n",
        "        gradient_checkpointing=True\n",
        "    )\n",
        "\n",
        "    trainer = RealNetTrainer(model, lr=lr, device=device, gradient_persistence=0.0, synaptic_noise=0)\n",
        "\n",
        "    return model, trainer, input_ids, output_ids\n",
        "\n",
        "def calculate_optimal_batch_size(device, num_neurons, activation, seq_len, think_gap, truncated_bptt_seq_len):\n",
        "    \"\"\"Calculates optimal batch size based on VRAM capacity.\"\"\"\n",
        "    print(\"\\nâš–ï¸  Auto-Tuning Batch Size...\")\n",
        "\n",
        "    if device == 'cpu':\n",
        "        return 32\n",
        "\n",
        "    if device == 'cuda':\n",
        "        t = torch.cuda.get_device_properties(0).total_memory\n",
        "        a = torch.cuda.memory_allocated(0)\n",
        "        free_vram = t - a\n",
        "\n",
        "        print(f\"   VRAM Total: {t / 1e9:.2f} GB\")\n",
        "        print(f\"   VRAM Free:  {free_vram / 1e9:.2f} GB (Allocated: {a / 1e9:.2f} GB)\")\n",
        "\n",
        "        # Heuristic: Bytes per neuron per step (FP16 Activations + Grads + Overhead)\n",
        "        # Native Mode: We only store activations for (Batch, SeqLen) now! (Outputs are decimated)\n",
        "        # However, internal gradients still track through time.\n",
        "        BYTES_PER_NEURON_STEP = 12\n",
        "\n",
        "        if truncated_bptt_seq_len > 0:\n",
        "            # We process raw tokens but computation graph is deep\n",
        "            effective_mem_len = truncated_bptt_seq_len * (think_gap + 1)\n",
        "        else:\n",
        "            effective_mem_len = seq_len * (think_gap + 1)\n",
        "\n",
        "        mem_per_sample = effective_mem_len * num_neurons * BYTES_PER_NEURON_STEP\n",
        "        safe_vram = free_vram * 0.85\n",
        "\n",
        "        calc_batch = int(safe_vram / mem_per_sample) if mem_per_sample > 0 else 1\n",
        "        calc_batch = max(1, calc_batch)\n",
        "\n",
        "        if calc_batch > 8:\n",
        "            calc_batch = (calc_batch // 8) * 8\n",
        "\n",
        "        print(f\"   Est. Memory/Sample: {mem_per_sample / 1e6:.2f} MB\")\n",
        "        print(f\"   Optimal Batch Size: {calc_batch}\")\n",
        "\n",
        "        return calc_batch\n",
        "    return 32\n",
        "\n",
        "def main():\n",
        "    global NUM_NEURONS, BATCH_SIZE # Allow updating global config if needed\n",
        "\n",
        "    print(f\"ðŸš€ RealNet-1B (FineWeb Streaming) - NATIVE THINKING MODE\")\n",
        "    print(f\"--- Configuration ---\")\n",
        "    print(f\"SEQ_LEN: {SEQ_LEN}\")\n",
        "    print(f\"BATCH_SIZE: {BATCH_SIZE} (Will Auto-Tune if -1)\")\n",
        "    print(f\"NUM_NEURONS: {NUM_NEURONS}\")\n",
        "    print(f\"TRUNCATED_BPTT_SEQ_LEN (Tokens): {TRUNCATED_BPTT_SEQ_LEN}\")\n",
        "    print(f\"STEPS_PER_EPOCH: {STEPS_PER_EPOCH}\")\n",
        "    print(f\"LOG_INTERVAL: {LOG_INTERVAL}\")\n",
        "    print(f\"MAX_START_SKIP: {MAX_START_SKIP}\")\n",
        "    print(f\"RESET_DATA_ITER: {RESET_DATA_ITER}\")\n",
        "    print(f\"GENERATION_LENGTH: {GENERATION_LENGTH}\")\n",
        "    print(f\"THINK_GAP: {THINK_GAP}\")\n",
        "    print(f\"ACTIVATION: {ACTIVATION}\")\n",
        "    print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n",
        "    print(f\"DEVICE: {DEVICE}\")\n",
        "    print(f\"NEUROGENESIS: Enabled={NEUROGENESIS_ENABLED}, MaxLossInc={MAX_LOSS_INCREASE}, Amount={NEUROGENESIS_AMOUNT}\")\n",
        "    if DARWINIAN_REGENERATION:\n",
        "        regen_val = f\"{REGENERATION_PERCENTAGE:.2%}\" if REGENERATION_MODE == 'percentage' else f\"{REGENERATION_THRESHOLD}\"\n",
        "        print(f\"PHOENIX (Regeneration): Mode={REGENERATION_MODE}, Val={regen_val}, Interval={REGENERATION_INTERVAL}\")\n",
        "    else:\n",
        "        print(f\"PHOENIX (Regeneration): Disabled\")\n",
        "    print(f\"RESET_OPTIM_ON_LOAD: {RESET_OPTIMIZER_ON_LOAD}\")\n",
        "    print(f\"SCHEDULER: Enabled={USE_SCHEDULER}, T0={SCHEDULER_T0}, MinLR={SCHEDULER_ETA_MIN}\")\n",
        "    print(f\"LEARNING_RATE: {LEARNING_RATE}\")\n",
        "    print(f\"OVERWRITE_LR_OF_CKPT: {OVERWRITE_LR_OF_CKPT}\")\n",
        "    print(f\"---------------------\")\n",
        "\n",
        "    # --- CHECKPOINT PRE-LOAD (For Data Resume) ---\n",
        "    CKPT_DIR = os.path.join('/content/drive/MyDrive/RealNet', 'ckpt')\n",
        "    os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "    CKPT_PATH = os.path.join(CKPT_DIR, f'llm_fineweb_{ACTIVATION}_latest.pth')\n",
        "    CKPT_BEST_PATH = os.path.join(CKPT_DIR, f'llm_fineweb_{ACTIVATION}_best.pth')\n",
        "\n",
        "    resume_doc_index = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    # --- CHECKPOINT PRE-LOAD (Dataset Resume) ---\n",
        "    if os.path.exists(CKPT_PATH):\n",
        "        try:\n",
        "             peek = torch.load(CKPT_PATH, map_location='cpu')\n",
        "             resume_doc_index = peek.get('dataset_step', 0)\n",
        "             if resume_doc_index > 0:\n",
        "                 print(f\"ðŸ“‚ Resuming dataset from index: {resume_doc_index}\")\n",
        "\n",
        "             start_epoch = peek.get('epoch', -1) + 1\n",
        "        except:\n",
        "             pass\n",
        "\n",
        "    dataset = FineWebIterableDataset(SEQ_LEN, skip_offset=resume_doc_index, debug=False)\n",
        "\n",
        "    # --- MODEL SETUP ---\n",
        "    model, trainer, input_ids, output_ids = initialize_system(dataset.get_vocab_size(), NUM_NEURONS, DEVICE, LEARNING_RATE, ACTIVATION)\n",
        "    NUM_NEURONS = model.num_neurons\n",
        "\n",
        "    # --- BATCH SIZE OPTIMIZATION ---\n",
        "    if BATCH_SIZE == -1:\n",
        "         BATCH_SIZE = calculate_optimal_batch_size(\n",
        "             DEVICE,\n",
        "             NUM_NEURONS,\n",
        "             ACTIVATION,\n",
        "             SEQ_LEN,\n",
        "             THINK_GAP,\n",
        "             TRUNCATED_BPTT_SEQ_LEN\n",
        "         )\n",
        "\n",
        "    # DataLoader for IterableDataset\n",
        "    # Streaming with 1 worker allows background downloading without duplication\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=1,        # 1 Background process for downloading\n",
        "        prefetch_factor=4,    # Buffer 4 batches ahead in RAM\n",
        "        persistent_workers=True, # Keep connection alive\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Input IDs: {input_ids[0]}-{input_ids[-1]}\")\n",
        "    print(f\"Output IDs: {output_ids[0]}-{output_ids[-1]}\")\n",
        "\n",
        "    # --- CHECKPOINT LOADING (Full) ---\n",
        "    if os.path.exists(CKPT_PATH):\n",
        "        # Pre-check dimensions to handle mismatches interactively\n",
        "        try:\n",
        "            ckpt_peek = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "            if 'model_state_dict' in ckpt_peek and 'W' in ckpt_peek['model_state_dict']:\n",
        "                saved_dim = ckpt_peek['model_state_dict']['W'].shape[0]\n",
        "\n",
        "                if saved_dim != NUM_NEURONS:\n",
        "                    print(f\"\\nâš ï¸ ARCHITECTURE MISMATCH DETECTED!\")\n",
        "                    print(f\"   Current Model: {NUM_NEURONS}\")\n",
        "                    print(f\"   Checkpoint:    {saved_dim}\")\n",
        "\n",
        "                    print(\"Select action:\")\n",
        "                    print(\"[1] Resize Model (Resume)\")\n",
        "                    print(\"[2] Transplant Weights (Adapt)\")\n",
        "                    print(\"[3] Start Fresh\")\n",
        "                    action = input(\"Choice [1/2/3]: \").strip()\n",
        "\n",
        "                    if action == '1':\n",
        "                        print(f\"ðŸ”„ Resizing to {saved_dim}...\")\n",
        "                        NUM_NEURONS = saved_dim\n",
        "                        model, trainer, _, _ = initialize_system(dataset.get_vocab_size(), NUM_NEURONS, DEVICE, LEARNING_RATE, ACTIVATION)\n",
        "                        opt_arg = None if RESET_OPTIMIZER_ON_LOAD else trainer.optimizer\n",
        "                        target_lr = LEARNING_RATE if OVERWRITE_LR_OF_CKPT else None\n",
        "                        load_checkpoint(model, opt_arg, CKPT_PATH, device=DEVICE, strict=True, lr=target_lr)\n",
        "                        print(f\"âœ… Resuming from Epoch {start_epoch}\")\n",
        "\n",
        "                    elif action == '2':\n",
        "                        print(f\"âš ï¸ Transplanting Weights...\")\n",
        "                        transplant_weights(model, CKPT_PATH, device=DEVICE)\n",
        "                        print(f\"ðŸ§¬ Transplant complete.\")\n",
        "\n",
        "                    else:\n",
        "                        print(\"ðŸ†• Starting fresh.\")\n",
        "                        start_epoch = 0\n",
        "                        dataset.skip_offset = 0\n",
        "\n",
        "                else:\n",
        "                    opt_arg = None if RESET_OPTIMIZER_ON_LOAD else trainer.optimizer\n",
        "                    target_lr = LEARNING_RATE if OVERWRITE_LR_OF_CKPT else None\n",
        "                    print(f\"ðŸ”„ Loading Checkpoint from {CKPT_PATH}...\")\n",
        "                    load_checkpoint(model, opt_arg, CKPT_PATH, device=DEVICE, strict=True, lr=target_lr)\n",
        "                    print(f\"âœ… Resuming from Epoch {start_epoch}\")\n",
        "            else:\n",
        "                 opt_arg = None if RESET_OPTIMIZER_ON_LOAD else trainer.optimizer\n",
        "                 target_lr = LEARNING_RATE if OVERWRITE_LR_OF_CKPT else None\n",
        "                 load_checkpoint(model, opt_arg, CKPT_PATH, device=DEVICE, strict=True, lr=target_lr)\n",
        "                 start_epoch = ckpt_peek.get('epoch', 0) + 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Failed to load/inspect checkpoint: {e}. Starting fresh.\")\n",
        "\n",
        "    # CrossEntropy\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
        "    trainer.loss_fn = criterion\n",
        "\n",
        "    # OUTPUT TRANSFORM: Flatten (Batch, Steps, Out) -> (N, Out)\n",
        "    def flatten_logits(out):\n",
        "        return out.reshape(-1, dataset.get_vocab_size())\n",
        "\n",
        "    # --- INITIAL TESTS ---\n",
        "    print(\"\\n--- GENERATION PREVIEW ---\")\n",
        "    try:\n",
        "        gen_text = generate(model, dataset, start_str=\"The meaning of life is\", length=100)\n",
        "        print(f\"Sample: {gen_text}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    print(\"--- TRAINING LOOP ---\")\n",
        "\n",
        "    epoch = start_epoch\n",
        "    prev_loss = float('inf')\n",
        "    loss_increase_counter = 0\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    if os.path.exists(CKPT_BEST_PATH):\n",
        "        try:\n",
        "            best_ckpt = torch.load(CKPT_BEST_PATH, map_location=DEVICE)\n",
        "            best_loss = best_ckpt.get('loss', float('inf'))\n",
        "            print(f\"ðŸ† Historical Best Loss: {best_loss:.4f}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    scheduler = None\n",
        "    if USE_SCHEDULER:\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            trainer.optimizer,\n",
        "            T_0=SCHEDULER_T0,\n",
        "            eta_min=SCHEDULER_ETA_MIN\n",
        "        )\n",
        "\n",
        "    data_iterator = iter(dataloader)\n",
        "\n",
        "    while True:\n",
        "        total_loss = 0\n",
        "        steps = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_idx in range(STEPS_PER_EPOCH):\n",
        "            try:\n",
        "                x, y, current_doc_tensor = next(data_iterator)\n",
        "                current_doc = current_doc_tensor[-1].item()\n",
        "                dataset.current_doc_index = current_doc\n",
        "            except StopIteration:\n",
        "                print(\"ðŸ”„ Restarting iterator...\")\n",
        "                data_iterator = iter(dataloader)\n",
        "                x, y, current_doc_tensor = next(data_iterator)\n",
        "                current_doc = current_doc_tensor[-1].item()\n",
        "                dataset.current_doc_index = current_doc\n",
        "\n",
        "            # Native Thinking Preparation\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE)\n",
        "            \n",
        "            y_flat = y.reshape(-1)\n",
        "            \n",
        "            seq_len = x.shape[1]\n",
        "            total_thinking_steps = seq_len * (THINK_GAP + 1)\n",
        "\n",
        "            if TRUNCATED_BPTT_SEQ_LEN != -1 and TRUNCATED_BPTT_SEQ_LEN > 0:\n",
        "                current_state = None\n",
        "                batch_loss = 0\n",
        "                steps_count = 0\n",
        "                \n",
        "                chunk_len = TRUNCATED_BPTT_SEQ_LEN\n",
        "                \n",
        "                for t_start in range(0, seq_len, chunk_len):\n",
        "                    t_end = min(t_start + chunk_len, seq_len)\n",
        "                    \n",
        "                    x_chunk = x[:, t_start:t_end]\n",
        "                    y_chunk_flat = y[:, t_start:t_end].reshape(-1)\n",
        "                    \n",
        "                    actual_tokens = t_end - t_start\n",
        "                    chunk_thinking_steps = actual_tokens * (THINK_GAP + 1)\n",
        "\n",
        "                    loss, current_state = trainer.train_batch(\n",
        "                        x_chunk,\n",
        "                        y_chunk_flat,\n",
        "                        thinking_steps=chunk_thinking_steps,\n",
        "                        full_sequence=True,\n",
        "                        output_transform=flatten_logits,\n",
        "                        initial_state=current_state,\n",
        "                        return_state=True\n",
        "                    )\n",
        "\n",
        "                    current_state = current_state.detach()\n",
        "                    batch_loss += loss\n",
        "                    steps_count += 1\n",
        "\n",
        "                loss = batch_loss / max(steps_count, 1)\n",
        "\n",
        "            else:\n",
        "                loss = trainer.train_batch(\n",
        "                    x,\n",
        "                    y_flat,\n",
        "                    thinking_steps=total_thinking_steps,\n",
        "                    full_sequence=True,\n",
        "                    output_transform=flatten_logits\n",
        "                )\n",
        "\n",
        "            # Scheduler Step\n",
        "            current_lr = 0.0\n",
        "            if USE_SCHEDULER and scheduler:\n",
        "                scheduler.step()\n",
        "                current_lr = scheduler.get_last_lr()[0]\n",
        "            elif trainer.optimizer:\n",
        "                current_lr = trainer.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            total_loss += loss\n",
        "            steps += 1\n",
        "\n",
        "            if batch_idx % LOG_INTERVAL == 0:\n",
        "                loss_val = loss.item() if isinstance(loss, torch.Tensor) else loss\n",
        "                ppl = np.exp(loss_val)\n",
        "                print(f\"Epoch {epoch} | Batch {batch_idx} | Doc #{current_doc} | Loss {loss:.4f} | PPL {ppl:.2f} | LR {current_lr:.2e}\")\n",
        "\n",
        "        avg_loss = total_loss / steps\n",
        "        avg_loss_val = avg_loss.item() if isinstance(avg_loss, torch.Tensor) else avg_loss\n",
        "        avg_ppl = np.exp(avg_loss_val)\n",
        "        print(f\"Epoch {epoch} Completed | Avg Loss: {avg_loss:.4f} | Avg PPL {avg_ppl:.2f} | Time: {time.time() - start_time:.1f}s\")\n",
        "\n",
        "        # --- PERIODIC GENERATION ---\n",
        "        print(\"--- GENERATION ---\")\n",
        "        try:\n",
        "            gen_text = generate(model, dataset, start_str=\"The meaning of life is \")\n",
        "            print(gen_text)\n",
        "        except Exception as e:\n",
        "            print(f\"Generation Error: {e}\")\n",
        "        print(\"------------------\")\n",
        "\n",
        "        # --- CHECKPOINT SAVING ---\n",
        "        ckpt_extra_data = {\n",
        "            'initial_lr': trainer.initial_lr,\n",
        "            'dataset_step': dataset.current_doc_index\n",
        "        }\n",
        "\n",
        "        save_checkpoint(model, trainer.optimizer, epoch, avg_loss, CKPT_PATH, extra_data=ckpt_extra_data)\n",
        "        print(f\"ðŸ’¾ Checkpoint Saved: {CKPT_PATH} (Doc Index: {dataset.current_doc_index})\")\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            save_checkpoint(model, trainer.optimizer, epoch, avg_loss, CKPT_BEST_PATH, extra_data=ckpt_extra_data)\n",
        "            print(f\"ðŸ† NEW RECORD! Saved: {CKPT_BEST_PATH} (Loss: {best_loss:.4f})\")\n",
        "\n",
        "        # --- NEUROGENESIS CONTROL ---\n",
        "        if NEUROGENESIS_ENABLED:\n",
        "            if avg_loss > prev_loss:\n",
        "                loss_increase_counter += 1\n",
        "                print(f\"âš ï¸ Loss Increased ({loss_increase_counter}/{MAX_LOSS_INCREASE})\")\n",
        "\n",
        "            if loss_increase_counter >= MAX_LOSS_INCREASE:\n",
        "                print(f\"ðŸ§¬ Expanding Network (Neurogenesis)...\")\n",
        "                trainer.expand(amount=NEUROGENESIS_AMOUNT)\n",
        "                NUM_NEURONS = model.num_neurons\n",
        "                loss_increase_counter = 0\n",
        "                prev_loss = float('inf')\n",
        "\n",
        "                if USE_SCHEDULER:\n",
        "                    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "                        trainer.optimizer, T_0=SCHEDULER_T0, eta_min=SCHEDULER_ETA_MIN)\n",
        "            else:\n",
        "                prev_loss = avg_loss\n",
        "\n",
        "        # --- REGENERATION CONTROL (PHOENIX) ---\n",
        "        if DARWINIAN_REGENERATION and epoch % REGENERATION_INTERVAL == 0:\n",
        "            print(f\"ðŸ”¥ Phoenix Protocol: Checking for dead synapses...\")\n",
        "\n",
        "            p_arg = REGENERATION_PERCENTAGE if REGENERATION_MODE == 'percentage' else None\n",
        "            t_arg = REGENERATION_THRESHOLD\n",
        "\n",
        "            revived, total = trainer.regenerate_synapses(threshold=t_arg, percentage=p_arg)\n",
        "\n",
        "            if revived > 0:\n",
        "                print(f\"ðŸ”¥ Reborn: {revived}/{total} ({revived/total:.2%}) synapses regenerated.\")\n",
        "                prev_loss = float('inf')\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001564ca5bad41ffa72454dabaf10015": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aca8bf099704960a33f8b1ef88bea83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5c34f495834524a1a077b67fa35ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e3ec207041b4ee09557f5027401e4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e48976ffbd1499c929d2430f9f5d36d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a967241441664c6a894833737472068c",
            "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
          }
        },
        "24aeaa3ab0fc4110a839eca4ad2bdd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27bddea9e66e447bad34eed9d9af84e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4480b16cb46242d68dd98d5fb13355d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2dba098822d406a94971f039bec6eea",
            "value": "â€‡26.4k/?â€‡[00:00&lt;00:00,â€‡2.82MB/s]"
          }
        },
        "3cba134770e14193b57a4b03a6879ace": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e01134b61948508d8fdeb540ab3a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4480b16cb46242d68dd98d5fb13355d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b7e7e6516243a99be1ec6b3ecc28ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e48976ffbd1499c929d2430f9f5d36d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe44d116771413086fb53d506c66ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9df4e339a22d492f9a4f4967affdbf97",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_46b7e7e6516243a99be1ec6b3ecc28ae",
            "value": "README.md:â€‡"
          }
        },
        "66510255473747c39f0ca25c949889cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dbbe4a819ef48598ab9a07cd1a3bf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e76caf009a249bf9d8316329b7e2518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11cb5c9dc474353b17c776372af38f0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bd22b2a7616f4c9e9463dc1ab0f7bd6e",
            "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
          }
        },
        "7b76f4aee386460bab874dcde2c68731": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2af97eeb1124f248c6a099803e7ff86",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_001564ca5bad41ffa72454dabaf10015",
            "value": "â€‡50/50â€‡[00:00&lt;00:00,â€‡6163.92it/s]"
          }
        },
        "9df4e339a22d492f9a4f4967affdbf97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a967241441664c6a894833737472068c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b233baea8150447daf079c651075c504": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2dba098822d406a94971f039bec6eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3b402f5c0d444c5a1e900c765703188": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f9197effdd4b309f4642c4d7790226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf9dedf22bd451097dee8d13827f024",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dbbe4a819ef48598ab9a07cd1a3bf54",
            "value": 1
          }
        },
        "b91b9b0026d64f838c5bb739f4544105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fe44d116771413086fb53d506c66ae3",
              "IPY_MODEL_b4f9197effdd4b309f4642c4d7790226",
              "IPY_MODEL_27bddea9e66e447bad34eed9d9af84e9"
            ],
            "layout": "IPY_MODEL_3cba134770e14193b57a4b03a6879ace"
          }
        },
        "bd22b2a7616f4c9e9463dc1ab0f7bd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2af97eeb1124f248c6a099803e7ff86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e8c88f568440e997a795badb70657c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e3cba64b0147a9bcbc56961f48727e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42e01134b61948508d8fdeb540ab3a07",
            "value": "â€‡2410/2410â€‡[00:00&lt;00:00,â€‡â€‡7.10it/s]"
          }
        },
        "e1887135234b4cf4915691160febfa82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aca8bf099704960a33f8b1ef88bea83",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66510255473747c39f0ca25c949889cb",
            "value": 50
          }
        },
        "ebe90f94272341028a42036b48718e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e3ec207041b4ee09557f5027401e4a6",
              "IPY_MODEL_efe5028be49745f49ac232357608b09f",
              "IPY_MODEL_d7e8c88f568440e997a795badb70657c"
            ],
            "layout": "IPY_MODEL_b3b402f5c0d444c5a1e900c765703188"
          }
        },
        "edf9dedf22bd451097dee8d13827f024": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "efe5028be49745f49ac232357608b09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24aeaa3ab0fc4110a839eca4ad2bdd8f",
            "max": 2410,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d5c34f495834524a1a077b67fa35ee7",
            "value": 2410
          }
        },
        "f0e3cba64b0147a9bcbc56961f48727e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11cb5c9dc474353b17c776372af38f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b63ee58f744648908003d21033e61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e76caf009a249bf9d8316329b7e2518",
              "IPY_MODEL_e1887135234b4cf4915691160febfa82",
              "IPY_MODEL_7b76f4aee386460bab874dcde2c68731"
            ],
            "layout": "IPY_MODEL_b233baea8150447daf079c651075c504"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
